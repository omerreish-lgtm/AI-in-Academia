# דפוסי שימוש של סטודנטים בכלי AI באקדמיה: מידול התופעה

**מהפכה שקטה מתחוללת באקדמיה**: נכון ל-2025, **86% מהסטודנטים** בעולם משתמשים בכלי AI בלימודיהם, ו-**25%** עושים זאת באופן יומי. הדו"ח הנוכחי ממפה את המצב הקיים, מסווג את דפוסי השימוש, ומזהה פערים בין בעלי העניין השונים – מבלי להעריך אם התופעה "טובה" או "רעה". המחקר מתמקד ב-80% מתוכנו בשימושי הסטודנטים עצמם, תוך שכבות גיאוגרפיות: עולם, ישראל ותחום המשפטים. הממצא המרכזי: קיים פער משמעותי בין היקף השימוש בפועל לבין המוּדעות המוסדית, ובישראל – פער נוסף של היעדר מדיניות לאומית כמעט מוחלט.

---

## חלק א': מידול שימוש סטודנטים ב-AI

### 1.1 סיווג Use Cases לפי סוג משימה אקדמית

מחקרים אמפיריים מ-2024-2025 מאפשרים לזהות ולסווג את השימושים העיקריים שסטודנטים עושים בכלי AI. הסיווג מבוסס על סקר Digital Education Council (3,839 סטודנטים ב-16 מדינות), סקר HEPI/Kortext (1,041 סטודנטים בבריטניה), וסקר UC System (53,450 סטודנטים בקליפורניה).

**הכנה לשיעור וקריאת חומרים** מהווה את השימוש הנפוץ ביותר. **58%** מהסטודנטים משתמשים ב-AI להסברת מושגים, ו-**48%** לסיכום מאמרים וספרי לימוד. סטודנטים מדווחים על שימוש ב-AI כ"מורה פרטי" זמין 24/7, המסוגל להסביר חומר מורכב בשפה פשוטה יותר.

**כתיבת עבודות** רשמה עלייה חדה בין 2024 ל-2025. על פי סקר HEPI, שימוש ב-AI ליצירת טקסט (text generation) **הוכפל מ-30% ל-64%** תוך שנה אחת. **24%** מהסטודנטים מדווחים על שימוש ב-AI ליצירת טיוטה ראשונה. יחד עם זאת, **18%** מהסטודנטים בבריטניה הודו שהכניסו טקסט שנוצר על-ידי AI ישירות לעבודות ללא שינוי משמעותי.

**פתרון תרגילים והכנה לבחינות** נמצאים גם הם בשימוש נרחב. **51%** מסטודנטי UC משתמשים ב-AI לסיעור מוחות לפרויקטי כתיבה, **51%+** למחקר נושאים, ו-**51%+** לחזרה לבחינות. מעניין לציין שבקרב בני נוער אמריקאים, **54%** רואים בשימוש ב-AI לחקירת נושאים חדשים כלגיטימי, אך רק **18%** רואים כך שימוש לכתיבת חיבורים.

**מחקר עצמאי** כולל שימוש ב-AI להצעת רעיונות למחקר (**41%**), זיהוי מקורות רלוונטיים, וניסוח שאלות מחקר. סטודנטים מדווחים על שימוש בכלים כמו Perplexity לאיתור ספרות אקדמית.

### טבלת סיווג לפי רמת מעורבות AI

| רמה | תיאור | אחוז הסטודנטים המשתמשים | דוגמאות מעשיות |
|-----|-------|-------------------------|----------------|
| **0** | אין שימוש | 14-35% (תלוי מדינה) | לימוד עצמאי מלא |
| **1** | עזר (Assistant) | ~60% | שאילת שאלות הבהרה, תרגום, חיפוש מידע בסיסי |
| **2** | שותף (Partner) | ~40% | עריכה, שיפור ניסוחים, קבלת משוב על טיוטות |
| **3** | מייצר (Generator) | 24-30% | יצירת טיוטות ראשוניות, הצעות לטקסט |
| **4** | מחליף (Replacer) | ~18% | העתקת output עם שינויים מינימליים |

### העדפות כלים: ChatGPT שולט

החלוקה בין כלי ה-AI מראה דומיננטיות ברורה של ChatGPT. על פי סקר Digital Education Council 2024:

- **ChatGPT**: 66% (מוביל מובהק)
- **Grammarly**: 25%
- **Microsoft Copilot**: 25%
- **Google Gemini**: נתח קטן אך עולה
- **Claude**: שימוש מוגבל בקרב סטודנטים

הסטודנט הממוצע משתמש ב-**2.1 כלי AI** ללימודים. מגמה חדשה מ-2025: פלטפורמות כמו Chegg משלבות מספר מודלים (ChatGPT, Gemini, Claude) זה לצד זה, ו-OpenAI השיקה "מצב לימוד" (study mode) המיועד במיוחד לסטודנטים.

### 1.2 נתונים כמותיים: הנתונים המרכזיים

**שיעורי אימוץ כוללים** הפתיעו חוקרים בהיקפם:

| מקור | מדגם | שנה | שיעור שימוש |
|------|------|-----|-------------|
| Digital Education Council | 3,839 סטודנטים, 16 מדינות | 2024 | **86%** |
| HEPI/Kortext (בריטניה) | 1,041 סטודנטים | 2025 | **92%** (עלייה מ-66% ב-2024) |
| Chegg Global | 11,706 סטודנטים, 15 מדינות | 2025 | **80%** |
| UC System | 53,450 סטודנטים | 2024 | **65%** |
| Tyton Partners | 3,000+ משיבים | 2024 | **59%** חודשי |

**תדירות השימוש** מראה דפוס של שימוש תכוף: **25%** משתמשים יומית, **54%** שבועית. שימוש ב-AI להגשות (assessments) עלה מ-**53% ל-88%** בין 2024 ל-2025 בבריטניה.

**התפלגות לפי תחום לימוד** מגלה פערים: הנדסה ומדעי המחשב מובילים עם **78%** שיעור שימוש ו-**8%** שימוש יומי. מדעי הרוח (humanities) בתחתית עם **52%** בלבד. סטודנטים למנהל עסקים (business) הם המשתמשים הנפוצים ביותר (**62%** לעבודות), והכי פחות נוטים לראות שימוש ב-AI כרמאות.

**התפלגות לפי שנתון**: השימוש עולה עם שנת הלימודים – מ-**~60%** בשנה א' ל-**70%** בשנים מתקדמות. סטודנטים בשנה ראשונה הם השמרניים ביותר.

### פערים דמוגרפיים בשימוש

**מגדר**: גברים משתמשים ב-AI **ב-14 נקודות אחוז יותר** מנשים. ב-UC System: 70%+ מהגברים לעומת 63% מהנשים. נשים מביעות יותר חששות מהאשמה ברמאות ומהזיות (hallucinations).

**מצב סוציו-אקונומי**: סטודנטים מרקע נמוך משתמשים פחות – **61%** ממקבלי Pell Grant לעומת **68%** ממי שלא מקבלים. זהו פער דיגיטלי חדש.

**סטודנטים בינלאומיים**: מובילים בשימוש – 10% שימוש תדיר, 77% שימוש מזדמן.

### 1.3 מניעים לשימוש: למה סטודנטים פונים ל-AI?

סקר HEPI 2025 זיהה את המניעים העיקריים:

**חיסכון בזמן** הוא המניע המרכזי – **51%** מהמשיבים. סטודנטים מתמודדים עם עומס אקדמי גובר ורואים ב-AI דרך להתייעל.

**שיפור איכות התוצר** מדורג שני – **50%**. סטודנטים מאמינים ש-AI מסייע לשפר ניסוחים, למצוא שגיאות, ולהעלות את רמת העבודות.

**תמיכה מותאמת אישית וזמינה** – **29%**. הגישה לעזרה 24/7, מחוץ לשעות הקבלה המסורתיות, מושכת סטודנטים רבים.

מנגד, **מה מרתיע סטודנטים?**
- **53%** חוששים מהאשמה ברמאות
- **51%** מודאגים מתוצאות שגויות/הזיות
- **59%** מודאגים מפגיעה בחשיבה ביקורתית
- **49%** חוששים מהתמכרות לכלים

### פער ציפיות: מה סטודנטים רוצים מהמוסדות?

**80%** מהסטודנטים אומרים שהאינטגרציה של AI במוסד לא עונה על הציפיות. **53%** סבורים שהמוסד צריך לספק כלי AI (עלייה מ-30% ב-2024), אך רק **26%** אומרים שהמוסד שלהם עושה זאת בפועל. **58%** מרגישים שאין להם מספיק ידע ומיומנויות ב-AI.

### 1.4 דפוסים ייחודיים לסטודנטים למשפטים

סטודנטים למשפטים מציגים דפוסי שימוש ייחודיים הנובעים מאופי התחום. מחקר מ-2024 מראה שלמעשה, **סטודנטים למשפטים פחות מעורבים עם AI** מעורכי דין מתרגלים – ייתכן בשל חששות מאי-דיוק במקורות.

**Use Cases ייחודיים למשפטים:**

**מחקר משפטי** כולל חיפוש פסיקה ותקדימים, הבנת מושגים משפטיים מורכבים, סקירת חקיקה השוואתית, ושימוש בכלים ייעודיים כמו Lexis+ AI ו-Westlaw CoCounsel.

**כתיבה משפטית** מתמקדת בכתיבת מזכרים בפורמט IRAC/CREAC, ניסוח כתבי טענות, כתיבת חוזים, ומכתבים ללקוחות.

**ניתוח פסקי דין** (Case Briefing) – יצירת סיכומי פסקי דין מובנים (עובדות, החלטה, הנמקה), זיהוי סוגיות משפטיות (issue spotting), וציר זמן של אירועים.

**הכנה לבחינות** כוללת תרגול IRAC, תרגילי issue spotting, יצירת מתארים (outlines), והכנת טיעוני נגד.

### בעיית ההזיות – האתגר המרכזי בתחום המשפטים

מחקר "Large Legal Fictions" (Stanford/Yale, 2024) חשף נתונים מטרידים:

| מודל | שיעור הזיות בשאילתות משפטיות |
|------|------------------------------|
| Llama 2 | **88%** |
| ChatGPT 3.5 | **69%** |
| ChatGPT 4 | **58%** |
| Lexis+ AI | **17%+** |
| Westlaw AI | **33%+** |

המודלים יוצרים **תקדימים שאינם קיימים** ("המצאת פסקי דין"), מצטטים **פרשנויות שגויות**, ומשלבים **מראי מקום פיקטיביים**. **75%+** מהתשובות על "החלטות בית משפט" שגויות.

**מקרי סנקציות בולטים (2023-2025):**
- *Mata v. Avianca* (2023): קנס $5,000 – המקרה הראשון; ChatGPT המציא 6 פסקי דין
- *Wadsworth v. Walmart* (2025): קנס $3,000 – משרד Morgan & Morgan; 8 אסמכתאות בדויות
- **486 מקרים מתועדים** גלובלית של הזיות AI בבתי משפט (324 בארה"ב)

### כלי AI ייעודיים למשפטים

| כלי | ספק | תכונות מרכזיות |
|-----|-----|-----------------|
| **Lexis+ AI Protégé** | LexisNexis | ניסוח, מחקר, סיכום, שאלות לחקירות; מבוסס RAG |
| **Westlaw CoCounsel** | Thomson Reuters | סקירת מסמכים, מחקר משפטי, ניתוח חוזים |
| **Harvey AI** | עצמאי | אימון מותאם על מסמכי משרד |
| **Vincent AI** | vLex | מחקר משפטי גלובלי |
| **Clearbrief** | עצמאי | אימות אסמכתאות, זיהוי הזיות |

### מיומנויות ספציפיות למשפטים בסיכון

הדיון בספרות מזהה מספר מיומנויות שעשויות להיפגע משימוש מוגזם ב-AI:
- **כתיבה משפטית אנליטית** – ChatGPT מייצר "דוגמאות גרועות" של IRAC
- **אימות מקורות** (Bluebook) – AI נכשל בפורמט ציטוט מדויק
- **חשיבה ביקורתית** – חשש ש-AI יהפוך ל"קביים"
- **הכנה לבחינת הלשכה** – אסור להסתמך על AI בבחינה

---

## חלק ב': המצב בעולם

### 2.1 מחקרים אמפיריים מרכזיים

**סקר Digital Education Council 2024** הוא המחקר הגלובלי המקיף ביותר עד כה – 3,839 סטודנטים מ-16 מדינות. הממצאים מצביעים על אימוץ מהיר ומסיבי: 86% שימוש כולל, ChatGPT דומיננטי, ופער בין ציפיות סטודנטים למה שמוסדות מספקים.

**סקר HEPI/Kortext 2025** בבריטניה מתעד שינוי דרמטי תוך שנה אחת: עלייה מ-66% ל-92% בשימוש כולל, הכפלה בשימוש ליצירת טקסט (30%→64%), ועלייה משמעותית בשימוש להגשות (53%→88%).

**סקר ABA על חינוך משפטי 2024** בדק 29 דיקנים/אנשי סגל במשפטים: **55%** מפקולטות המשפטים מציעות קורסי AI ייעודיים, **83%** מספקות הזדמנויות לימודיות, **69%** עדכנו מדיניות יושרה אקדמית.

**מחקר PLOS ONE 2024** סקר 23,218 סטודנטים מ-109 מדינות – המחקר הגלובלי הגדול ביותר, המאפשר השוואות בין-לאומיות.

### 2.2 מדיניות מוסדות מובילים

מיפוי המדיניות בעולם מגלה ספקטרום רחב – מגישות מתירניות ועד מגבילות. להלן תיאור עובדתי ללא הערכה.

**בתי ספר למשפטים בארה"ב:**

**Harvard Law School** (2024-25): איסור ברירת מחדל בבחינות ועבודות; מרצים יכולים להתיר עם גילוי; חובת דיווח על שימוש בכלי AI.

**Stanford Law School**: שיקול דעת ברמת המרצה; בהיעדר הנחיה ברורה – שימוש ב-AI נחשב כ"עזרה מאדם אחר"; קבוצת עבודה לאינטגריטי אקדמי (AIWG) מספקת הנחיות מתמשכות.

**Columbia Law School** (אפקטיבי מאוגוסט 2025): **איסור ברירת מחדל** בבחינות, עבודות סיום, וכל ניסוח לזכות אקדמי – גם אם מתועד. מותר ללימוד, סיעור מוחות, זיהוי שגיאות כתיב.

**Yale Law School**: מדיניות ברמת הקורס; אין איסור מפורש; מרצים קובעים מדיניות פרטנית.

**אוניברסיטאות בבריטניה:**

**Oxford** (ינואר 2024, עדכון יולי 2025): מבוססת על עקרונות Russell Group; AI יכול לתמוך בלמידה אם נעשה שימוש אתי; שימוש לא מורשה = פלגיאט; גישה ל-ChatGPT Edu, Gemini, Copilot.

**Cambridge**: אימצה עקרונות Russell Group; שימוש ב-AI בעבודות מוערכות = עבירת משמעת; נוצרה קטגוריית עבירה חדשה "AI" ב-2024.

**LSE**: מערכת תלת-שכבתית – ברירת מחדל: איסור בהערכות; מחלקות יכולות להגדיר שימוש מורשה; מכון Data Science מתיר AI אלא אם נאמר אחרת.

**אוסטרליה:**

**University of Melbourne**: שימוש ב-AI ליצירת חומר המוצג כעבודה עצמית = "רמאות מכוונת ועבירת משמעת אקדמית"; מפעילה גלאי AI של Turnitin מאפריל 2023.

**UNSW**: פיתחה **מסגרת רמות סיוע AI** (Levels of AI Assistance Framework) – מערכת מקיפה עם 4 רמות; דרישה לפירוט ברמת הקורס; מדגישה עקרונות אתיים.

**אירופה:**

**ETH Zurich** (יולי 2024, עדכון דצמבר 2024): גישה פרואקטיבית התומכת בשימוש אחראי; עקרונות אחריות, שקיפות והגינות; חובת הצהרה על שימוש ב-GenAI; Microsoft Copilot בסביבה מוגנת.

**European University Association**: עמדה כי כל ניסיון לאסור AI "יהיה ללא תועלת"; המגזר חייב להתאים גישות; תוכנית עבודה ייעודית ל-AI (2024-2025).

### עקרונות Russell Group – מסגרת בריטית מרכזית

חמישה עקרונות שאומצו על ידי 24 אוניברסיטאות מחקר מובילות בבריטניה (יולי 2023):
1. תמיכה בסטודנטים וסגל להפוך אוריינים ב-AI
2. הכשרת סגל לתמוך בשימוש מתאים
3. התאמת הוראה והערכה לשימוש אתי
4. הבטחת קפדנות אקדמית ויושרה
5. שיתוף פעולה לשיתוף best practices

### 2.3 עמדות גופים מקצועיים

**American Bar Association (ABA)**

**חוות דעת פורמלית 512** (יולי 2024) – ההנחיה האתית הראשונה על AI גנרטיבי:

| כלל מודל | הנחיה |
|----------|-------|
| **1.1 (מיומנות)** | חובה להבין יכולות ומגבלות AI; לאמת פלטים באופן עצמאי |
| **1.6 (סודיות)** | להעריך סיכוני חשיפה; לקרוא תנאי שימוש; להבחין בין AI "פתוח" ל"סגור" |
| **1.4 (תקשורת)** | לגלות ללקוחות על שימוש ב-AI כשרלוונטי |
| **1.5 (שכר טרחה)** | אין לגבות על לימוד כלי AI כלליים; לחייב זמן עבודה בפועל |
| **פיקוח** | כללי פיקוח קיימים על צדדים שלישיים חלים על עבודה בסיוע AI |

**UK Solicitors Regulation Authority (SRA)**

דו"ח Risk Outlook (2023-2024): AI בעל "פוטנציאל גבוה מאוד" אך סיכונים חייבים להיות מנוהלים. עורכי דין נותרים אחראים ללא קשר לשימוש ב-AI. יש לפקח על AI כמו על עובד זוטר. אישרה משרד עורכי דין ראשון מבוסס-AI (Garfield.Law Ltd).

**UK Law Society**

הנחיות "Generative AI – The Essentials": AI אינו פוטר מחובות אתיות; עורכי דין חייבים להבין כיצד AI משתמש בנתונים; שמירה על מיומנות, פיקוח, ודיוק.

---

## חלק ג': המצב בישראל

### 3.1 מדיניות מוסדית

**המועצה להשכלה גבוהה (מל"ג)** מיקדה מאמצי AI בתשתית מחקר ופיתוח כישרונות – לא במדיניות שימוש סטודנטים:

**יוזמת AI לאומית**: תוכנית משותפת עם רשות החדשנות, משרד החדשנות ומערך הפיתוח הביטחוני. תקציב: כמיליארד ₪ עד 2027. מיקוד: מרכזי מחקר AI ב-7 אוניברסיטאות, מלגות לדוקטורנטים, פוסט-דוק, תשתית מחשוב.

**מה המל"ג לא עשתה**: לא פורסמו הנחיות לאומיות על שימוש סטודנטים ב-AI; אין מסגרת ליושרה אקדמית בעידן ה-GenAI; אין דרישות גילוי מחייבות.

**דו"ח מבקר המדינה (נובמבר 2024)** ביקר את מוכנות ישראל הלאומית ל-AI, וציין פערים במדיניות ורגולציה ממשלתית.

### מדיניות אוניברסיטאות ישראליות

| אוניברסיטה | סטטוס מדיניות | תכונות מרכזיות |
|------------|---------------|-----------------|
| **אוניברסיטת בר-אילן** | ✅ מדיניות מקיפה | ברירת מחדל: שימוש מותר עם גילוי חובה; טופס הצהרה; משמעת על הפרות |
| **הטכניון** | ✅ מרכז משאבים | מרכז הוראה ולמידה יצר פורטל אתיקה ב-AI; הנחיות לשימוש אתי |
| **האוניברסיטה הפתוחה** | ✅ אתר משאבי AI | אתרים נפרדים לסגל ולסטודנטים; הדרכת אוריינות AI |
| **מכללת הרצוג** | ✅ מדיניות כתובה (פברואר 2025) | יעד אוריינות AI; מותר אלא אם אסור; דרישת גילוי |
| **האוניברסיטה העברית** | ⚠️ לא נמצאה מדיניות אחידה | יש תוכניות מחקר AI אך לא מדיניות שימוש סטודנטים |
| **אוניברסיטת תל אביב** | ⚠️ לא נמצאה מדיניות אחידה | יש Lab for Algorithmic Governance אך לא מסגרת שימוש סטודנטים |
| **אוניברסיטת בן-גוריון** | ❌ לא נמצא | אין מדיניות שימוש AI פורסמה |
| **אוניברסיטת חיפה** | ❌ לא נמצא | אין מדיניות שימוש AI פורסמה |
| **אוניברסיטת רייכמן** | ❌ לא נמצא | מרכז קריירה מזכיר "כלים רלוונטיים ל-AI" אך אין מדיניות |

### מודל בר-אילן – המדיניות המפורטת בישראל

מדיניות בית הספר ללימודי מחקר של אוניברסיטת בר-אילן היא המקיפה ביותר שנמצאה:

**כלל ברירת מחדל**: שימוש ב-AI **מותר** אלא אם המרצה אסר במפורש.

**טופס הצהרה חובה** עם אפשרויות לסמן:
- סיעור מוחות/רעיונות
- סיוע במחקר
- ניסוח תוכן
- שיפור שפה/סגנון
- פורמט ציטוטים
- ניתוח נתונים
- תרגום
- יצירת קוד
- הוכחות מתמטיות

**אחריות סטודנט**: כל תוכן שנוצר על-ידי AI חייב להיבדק; הסטודנט אחראי לשגיאות כולל "הזיות".

**הגנת פרטיות**: איסור על שיתוף מידע אישי/רגיש עם כלי AI.

**השלכות משמעתיות**: שימוש לא מורשה מטופל כהפרת יושרה אקדמית (כללי פלגיאט חלים).

**חדשנות**: בר-אילן השיקה צ'אטבוט "עוזר הוראה" מבוסס AI בפיילוט 2024.

### 3.2 פקולטות למשפטים בישראל

**אוניברסיטת תל אביב – הפקולטה למשפטים (בוכמן)**

**מחקר והוראה**: Lab for Algorithmic Governance (בראשות פרופ' ניבה אלקין-קורן ופרופ' אסף המדני) – חוקר משפט ו-AI. **תואר LLB עם מסלול AI/Data Science** – הראשון בישראל המשלב משפטים עם קורסי AI. פורסם כרך חדש "בינה מלאכותית במשפט הישראלי" בכתב העת *משפט, חברה ותרבות*.

**מדיניות שימוש סטודנטים**: ⚠️ לא פורסמה. לא נמצאה מדיניות פקולטטית על שימוש סטודנטים ב-AI.

**אוניברסיטת בר-אילן – הפקולטה למשפטים**

**מחקר**: BIU Lab for Law, Data-Science and Digital Ethics (ד"ר איתי בר-סימן-טוב).

**מדיניות שימוש**: נופלת תחת המדיניות האוניברסיטאית הכללית. דף הדרכה של הספרייה מפנה סטודנטים להנחיות האוניברסיטה ומציין סיכונים: הזיות, חששות פרטיות, אסמכתאות לא אמינות.

**פקולטות משפטים אחרות**: לא נמצאו מדיניות שימוש AI פורסמות באוניברסיטה העברית, חיפה, או מכללות משפטים אחרות.

### 3.3 דיון ציבורי בישראל

**מסמך עמדה: "השכלה גבוהה ו-GenAI בישראל"** (אוקטובר 2023)

פורסם על ידי הפקולטה לטכנולוגיות הוראה ב-HIT (מכון טכנולוגי חולון):

**ממצאי סקר (700 סטודנטים ישראליים, מאי 2023)**:
- **70% מהסטודנטים** משתמשים ב-GenAI בלימודים אקדמיים
- **95% משתמשים ב-ChatGPT** ככלי עיקרי
- שימושים עיקריים: קבלת רעיונות/השראה (3.01/5), הסבר תוכן (3.00/5), הכנת תרגילים
- **60%+ מהסטודנטים מאמינים** שמרצים אינם יכולים לצפות להתנהגות אתית ללא הדרכת AI
- ציטוט סטודנט: *"אני לא גונב מאף אחד, אני פשוט מכין את עצמי טוב יותר לעולם החיצון. חבל שהאקדמיה לא מבינה את זה."*

**המלצות המסמך** (לצורך תיעוד, לא המלצה):
1. פיתוח אסטרטגיות AI מוסדיות
2. הכשרת סגל באינטגרציית AI
3. מעבר להערכות מבוססות פרויקטים
4. בניית "אוריינות AI" לבוגרים

**סיקור תקשורתי**: מעריב/Ice (2024) סיקרו את בר-אילן כאוניברסיטה הראשונה לפרמל מדיניות AI. Ynet (2024) פרסם כתבה על פיילוט עוזר ההוראה של בר-אילן.

### 3.4 פערי מידע – מה לא ידוע על המצב בישראל

**פערים קריטיים:**

1. **היעדר הנחיות מל"ג**: בניגוד לבריטניה, האיחוד האירופי או האגודות המקצועיות בארה"ב, המל"ג לא הוציאה הנחיות על שימוש סטודנטים ב-AI. אין מסגרת לאומית ליושרה אקדמית בעידן ה-GenAI.

2. **מדיניות אוניברסיטאות מחקר לא זמינה**: האוניברסיטה העברית, אוניברסיטת תל אביב, אוניברסיטת בן-גוריון, אוניברסיטת חיפה – לא פורסמו מדיניות שימוש סטודנטים ב-AI.

3. **מדיניות ספציפית לפקולטות משפטים**: **אף פקולטה למשפטים בישראל** לא פרסמה הנחיות שימוש AI ייעודיות לסטודנטים למשפטים – בניגוד לבתי ספר למשפטים בארה"ב ובבריטניה.

4. **היעדר נתונים אמפיריים**:
   - אין סקרים פורסמים על שימוש סטודנטים למשפטים בישראל ב-AI ספציפית
   - אין מחקרים על יעילות גילוי AI באוניברסיטאות ישראליות
   - אין נתונים על מקרי משמעת הכוללים שימוש לרעה ב-AI

5. **עמדת לשכת עורכי הדין**: לא פורסמה הנחיה מהלשכה על AI בהכשרה משפטית או התמחות.

---

## חלק ד': ניתוח פערים

### 4.1 פער סטודנטים-מרצים

**תפיסת היקף השימוש**: הנתונים מצביעים על פער משמעותי בין השימוש בפועל לבין מה שמרצים מעריכים. בעוד **86-92%** מהסטודנטים משתמשים ב-AI, רבים מהמרצים עדיין לא עדכנו את הנחות העבודה שלהם. סקר HIT בישראל מצא ש-**70%** מהסטודנטים משתמשים ב-GenAI, אך לא נמצא מחקר מקביל על הערכות מרצים.

**הבנת יכולות הכלים**: מרצים נוטים לראות AI ככלי "רמאות" או "קיצור דרך", בעוד סטודנטים רואים בו כלי למידה לגיטימי. ציטוט סטודנט ישראלי: *"אני לא גונב מאף אחד, אני פשוט מכין את עצמי טוב יותר לעולם החיצון."*

**ציפיות ממשימות**: הפער מתבטא גם בציפיות ממשימות:
- סטודנטים רואים ב-AI דרך להתייעל ולשפר איכות
- מרצים עשויים לראות תוצרים "מלוטשים מדי" כחשודים
- **80%** מהסטודנטים מרגישים שהמוסד לא עונה על ציפיותיהם מאינטגרציית AI

**פער הדרכה**: **58%** מהסטודנטים מרגישים שאין להם מספיק ידע ומיומנויות ב-AI, אך רק **29%** מהמוסדות מערבים סטודנטים בדיוני אסטרטגיית AI.

### 4.2 פער מדיניות-פרקטיקה

**ברמה הגלובלית**: רק **19%** מהמוסדות יש מדיניות AI פורמלית, בעוד **42%** פיתוח מסגרות. זאת בעוד **86%** מהסטודנטים כבר משתמשים.

**בישראל**: הפער בולט במיוחד – רוב האוניברסיטאות הגדולות (עברית, תל אביב, בן-גוריון, חיפה) לא פרסמו מדיניות, בעוד הסקרים מצביעים על **70%** שימוש.

**פער גילוי ב-AI**: בבריטניה, **88%** מהסטודנטים משתמשים ב-AI להגשות, אך רק **18%** מודים שהכניסו טקסט AI ישירות. זה מצביע על פער בין שימוש בפועל לגילוי.

**פער אכיפה**: **76%** מהסטודנטים בבריטניה מאמינים שהמוסד שלהם יזהה שימוש ב-AI – אך מוסדות רבים (Stanford, Cambridge, Bath) דחו או הזהירו מפני כלי זיהוי בשל הטיה וחוסר אמינות.

### 4.3 פער ידע – מה המרצים יודעים ולא יודעים

**מה מרצים לרוב יודעים**:
- קיום כלי AI כמו ChatGPT
- חששות כלליים מרמאות
- שהסטודנטים "כנראה" משתמשים

**מה מרצים לרוב לא יודעים**:
- **היקף השימוש בפועל** – הנתונים מראים 86%+, גבוה מרוב ההערכות
- **מגוון השימושים** – לא רק "העתקה" אלא גם הסבר, עריכה, סיעור מוחות
- **יכולות וחולשות ספציפיות** של כל כלי
- **בעיית ההזיות** – במיוחד במשפטים (58-88% הזיות)
- **אופן השימוש** – 25% יומי, 54% שבועי
- **מניעים** – לא רק "עצלות" אלא יעילות, שיפור איכות, עומס

**פער ספציפי במשפטים**: מחקר מ-2024 מראה ש"סטודנטים למשפטים פחות מעורבים עם AI מעורכי דין מתרגלים" – מה שעשוי להפתיע מרצים שמניחים שסטודנטים מובילים באימוץ.

---

## חלק ה': מסגרות ניתוח קיימות

### 5.1 מסגרת 4D לשטף ב-AI

המסגרת הבולטת ביותר היא **4D Framework for AI Fluency**, שפותחה על ידי **Rick Dakan** (Ringling College of Art and Design) ו-**Joseph Feller** (University College Cork) **בשותפות עם Anthropic**.

**הבהרה**: המסגרת המקורית משתמשת ב-**Description** (תיאור) ולא ב-"Discretion" (שיקול דעת).

**ארבע הכישורים:**

| כישור | תיאור | יישום בהקשר אקדמי |
|-------|-------|-------------------|
| **Delegation** (האצלה) | קביעת מטרות והחלטה האם, מתי ואיך לעסוק עם AI | החלטה אילו משימות להאציל ל-AI ואילו לבצע עצמאית |
| **Description** (תיאור) | תיאור יעיל של מטרות להנחיית התנהגויות ופלטים שימושיים מ-AI | כתיבת פרומפטים אפקטיביים |
| **Discernment** (הבחנה) | הערכה מדויקת של שימושיות פלטי AI | זיהוי הזיות, שגיאות, חוסרים |
| **Diligence** (חריצות/אחריות) | לקיחת אחריות על מה שעושים עם AI ואיך | אחריות אתית, גילוי, אימות |

**שלושה מצבי אינטראקציה עם AI**:
- **Automation** (אוטומציה): AI מבצע משימות ספציפיות על פי הוראות אנושיות
- **Augmentation** (הגברה): בני אדם ו-AI משתפים פעולה כשותפי חשיבה
- **Agency** (סוכנות): בני אדם מגדירים AI לבצע משימות עתידיות באופן עצמאי

**פילוסופיה**: "שטף ב-AI משמעו התעסקות עם AI בדרכים **יעילות, אפקטיביות, אתיות ובטוחות**"

**יישום**: כבר יושם ב-5+ קורסים ב-Ringling College וב-Cork University Business School.

### 5.2 מסגרות UNESCO לכישורי AI

**מסגרת כישורי AI לסטודנטים** (ספטמבר 2024) כוללת **12 כישורים בארבעה ממדים**:

1. **מנטליות ממוקדת-אדם**: הבנה ומימוש סוכנות אנושית ביחס ל-AI
2. **אתיקה של AI**: הוראת שימוש אחראי, עיצוב-אתי, ופרקטיקות בטוחות
3. **טכניקות ויישומי AI**: ידע ומיומנויות AI בסיסיים
4. **עיצוב מערכות AI**: טיפוח פתרון בעיות, יצירתיות וחשיבה עיצובית

**מסגרת כישורי AI למורים** (ספטמבר 2024) כוללת **15 כישורים** לפיתוח מקצועי לאורך החיים.

**עקרונות מפתח**: גישה ממוקדת-אדם; AI צריך להשלים, לא להחליף, מורים; דגש על שיקולים אתיים, שקופים, לא-מפלים.

### 5.3 טקסונומיית Bloom מיושמת ל-AI

**Oregon State University – "Bloom's Taxonomy Revisited" (גרסה 2.0, 2024)**

מסווגת כל רמה קוגניטיבית לפי:
1. **מיומנויות אנושיות ייחודיות** – מה AI אינו יכול לעשות
2. **כיצד GenAI יכול להשלים למידה** – שימושי AI מתאימים

| רמה | מיומנויות אנושיות | השלמת GenAI |
|-----|-------------------|-------------|
| **יצירה** | מינוף חוויות חיים, אינטואיציה, רפלקציה | תמיכה בסיעור מוחות |
| **הערכה** | רפלקציה מטא-קוגניטיבית, שיפוט אתי | זיהוי יתרונות/חסרונות |
| **ניתוח** | חשיבה ביקורתית, הצדקת ניתוח | השוואה, חישוב, פרשנות |
| **יישום** | יישום בעולם האמיתי, ניסוי | סיוע בתהליכים, זיהוי שגיאות |
| **הבנה** | הקשר רגשי/מוסרי | תיאור מושגים, תרגום |
| **זכירה** | זכירה כשטכנולוגיה לא זמינה | אחזור עובדות, הגדרות |

**תובנה מפתח**: מיומנויות מסדר גבוה (יצירה, הערכה) מדגישות יכולות אנושיות, בעוד מיומנויות מסדר נמוך יכולות להיות יותר בסיוע AI.

### 5.4 מסגרות נוספות בספרות

**מסגרת MAGE**: מוזכרת על-ידי Oregon State להערכת איכות חשיבה ביקורתית AI. מנתחת יכולות ChatGPT 4 ברמות קוגניטיביות שונות.

**מסגרת מדיניות אקולוגית לחינוך AI** (מחקר אוניברסיטאות הונג קונג): שלושה ממדים – פדגוגי (שיטות הוראה, אסטרטגיות הערכה), ממשלי (פרטיות, אבטחה, אחריותיות), ותפעולי (תשתית והכשרה).

**מסגרת AILit** (נציבות אירופית ו-OECD): יוזמה משותפת לחינוך יסודי ותיכוני. גישה מבוססת-כישורים ל-K-12.

**טקסונומיה של שימוש ב-GenAI בכיתת כתיבה** (Springer, 2025): חמש קטגוריות עם רמות אתיות מתאימות – מאין שימוש ועד שימוש ללא דרישת בדיקה אנושית.

### 5.5 מסגרות ספציפיות לחינוך משפטי

לא נמצאה מסגרת "4D" ספציפית לחינוך משפטי עם Delegation-Discernment-Discretion-Diligence. עם זאת, זוהו מספר גישות:

**סקר ABA Task Force on AI and Legal Education** (יוני 2024): 69% עדכנו מדיניות יושרה אקדמית; 55% מציעות קורסי AI ייעודיים.

**גישות בתי ספר למשפטים**:
- **Suffolk University Law School**: גישת "AI Sandwich" – "הסטודנט חייב להיות הלחם משני הצדדים. מה הסטודנט מכניס, ואיך הפלט מוערך, חשוב יותר מהכלי באמצע."
- **Case Western Reserve**: הראשון לדרוש הסמכת AI לכל סטודנטי שנה א' (4 תוצאות למידה)
- **Stanford's CodeX**: סימולטור משא ומתן M&A לתרגול מעשי
- **Georgetown Law**: 17+ קורסי AI, גישת שיקול דעת מרצה

**אלמנטים משותפים בחינוך משפטי**:
1. הבנת יסודות AI ו-LLMs
2. יישומים מעשיים בפרקטיקה (מחקר, סקירת מסמכים, תחזית תיקים)
3. פרקטיקות מיטביות לניהול נתונים ולקוחות
4. שיקולים אתיים ועמידה ברגולציה
5. הערכה ביקורתית של פלטי AI (במיוחד הזיות/אסמכתאות)

---

## נספח: מקורות ומתודולוגיה

### מקורות ראשיים

**סקרים ומחקרים אמפיריים:**
- Digital Education Council Global AI Student Survey 2024 (3,839 סטודנטים, 16 מדינות)
- HEPI/Kortext Student Generative AI Survey 2025 (1,041 סטודנטים, בריטניה)
- UC System UCUES 2024 (53,450 סטודנטים, קליפורניה)
- Tyton Partners Time for Class 2024 (3,000+ משיבים)
- Pew Research Center 2024-2025 (ארה"ב)
- UNESCO Higher Education AI Survey 2025 (400 תשובות, 90 מדינות)
- ABA AI and Legal Education Survey 2024 (29 דיקנים/סגל)
- PLOS ONE Global Study 2024 (23,218 סטודנטים, 109 מדינות)
- סקר HIT על סטודנטים ישראליים (700 סטודנטים, מאי 2023)

**מחקרים על הזיות במשפטים:**
- Dahl et al., "Large Legal Fictions" (2024), Journal of Legal Analysis, Stanford/Yale
- Magesh et al., "Hallucination-Free?" (2025), Benchmarking legal AI tools

**מסמכי מדיניות:**
- ABA Formal Opinion 512 (יולי 2024)
- Russell Group Five Principles (יולי 2023)
- SRA Risk Outlook Report (2023-2024)
- Law Society "Generative AI – The Essentials"
- European University Association Position Statement (2023)
- מדיניות אוניברסיטת בר-אילן (graduate-school.biu.ac.il)
- ETH Zurich AI Guidelines (יולי 2024, דצמבר 2024)

**מסגרות:**
- Dakan \& Feller, 4D Framework for AI Fluency (2025), בשיתוף Anthropic
- UNESCO AI Competency Frameworks (ספטמבר 2024)
- Oregon State Bloom's Taxonomy Revisited (2024)

### מגבלות המחקר

1. **תלות בזמינות מקוונת**: מדיניות שלא פורסמה באינטרנט לא נכללה
2. **שפה**: מרבית המקורות באנגלית; מקורות בעברית מוגבלים
3. **עדכניות**: התחום משתנה במהירות; נתונים מתיישנים תוך חודשים
4. **הטיית דיווח עצמי**: סקרים מבוססי דיווח עצמי עשויים לחסר/לייתר
5. **מגבלת מדגם ישראלי**: סקר HIT היחיד שנמצא (700 סטודנטים, 2023)
6. **היעדר נתוני משפטים בישראל**: לא נמצאו מחקרים ייעודיים על סטודנטים למשפטים בישראל

### פערי מידע מזוהים

**ברמה הגלובלית:**
- נתונים מועטים על מדינות מתפתחות
- פער בין סקרים כמותיים למחקר איכותני עמוק
- נתונים מועטים על שימוש ארוך-טווח והשפעות

**ברמה הישראלית:**
- היעדר מדיניות מל"ג לשימוש סטודנטים
- רוב האוניברסיטאות ללא מדיניות פורסמת
- אף פקולטה למשפטים עם מדיניות ספציפית
- אין סקר עדכני (אחרון: מאי 2023)
- אין נתוני משמעת על מקרי AI
- אין עמדת לשכת עורכי הדין

**ברמת המשפטים:**
- פער בין נתונים על עורכי דין מתרגלים לבין סטודנטים למשפטים
- נתונים מועטים על כלים משפטיים ספציפיים ב-RAG
- חסר מחקר על יעילות הדרכת AI בבתי ספר למשפטים

---

**סיום**: דו"ח זה מיפה את התופעה של שימוש סטודנטים ב-AI באקדמיה, תוך זיהוי דפוסים, קטגוריות ופערים. הממצא המרכזי הוא שהתופעה מתקדמת מהר יותר מהתגובה המוסדית – בעולם ובמיוחד בישראל. בתחום המשפטים, האתגרים הייחודיים של הזיות ואסמכתאות מחייבים התייחסות ספציפית שטרם קיימת ברוב המוסדות.