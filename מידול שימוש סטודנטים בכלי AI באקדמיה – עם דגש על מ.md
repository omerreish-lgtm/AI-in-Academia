<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# מידול שימוש סטודנטים בכלי AI באקדמיה – עם דגש על משפטים

דצמבר 2025

***

## תקציר על – התמונה הכללית

במערכת ההשכלה הגבוהה כבר לא מדובר בשאלה האם סטודנטים משתמשים ב‑AI, אלא כיצד, כמה, ובאיזה פער מהציפיות והמדיניות של המוסדות.

מספר מגמות בולטות:

- ברמת העולם: בסקר גלובלי של ה‑Digital Education Council דיווחו 86% מהסטודנטים שהם משתמשים ב‑AI בלימודים; יותר ממחצית משתמשים לפחות פעם בשבוע, וכרבע משתמשים מדי יום.[^1][^2]
- בסקרים רחבים אחרים (Chegg, HEPI, Chegg / HEPI / Chegg) נרשם זינוק תוך שנה אחת מ‑53% ל‑88% שימוש ב‑GenAI בעבודות וערכות הערכה, ו‑92% שימוש כלשהו בכלי AI בקרב סטודנטים לתואר ראשון בבריטניה.[^3][^1]
- בישראל: סקר מהיר בירושלים ובמוסדות נוספים מצא שכ‑53% מהסטודנטים השתמשו ב‑AI כבר בתחילת 2023, ודיווח עיתונאי מאוחר יותר מציין שכ‑90% מהסטודנטים בישראל השתמשו בכלי AI במהלך סמסטר אחד, כ‑60% לא רואים בתוצרים אמינים מספיק וכמחצית חוששים שהשימוש ייתפס כרמאות.[^4][^5]
- סטודנטים למשפטים: בסקר של LexisNexis ב‑2023 כ‑44% מסטודנטים למשפטים דיווחו שהשתמשו ב‑GenAI בכלל, אך רק 9% משתמשים בו בפועל בלימודים ו‑25% מתכננים להשתמש בו בעתיד. כלומר – אימוץ נמוך יותר וחשדנות גבוהה יחסית לתחומים אחרים.[^6]

במקביל, סקרים רבים מראים:

- פער חד בין שימוש נרחב של סטודנטים לבין שימוש מצומצם, מהוסס ואף לא מיומן של מרצים.[^1]
- פער בין מדיניות מוצהרת (לעיתים מגבילה מאוד) לבין פרקטיקה בפועל, שבה רוב הסטודנטים משתמשים בכל זאת, לעיתים גם כשהשימוש מוגדר כהפרת יושרה אקדמית.[^7][^8][^3]
- התפתחות של מסגרות תיאורטיות וטקסונומיות לסיווג שימוש ב‑AI בחינוך, כולל מסגרת ה‑4D (Delegation, Description, Discernment, Diligence) כמודל לניתוח דפוסי השימוש.[^9][^10]

המשך המסמך בונה מודל תיאורי מקיף של דפוסי השימוש, וממפה את המצב ברמת העולם, ישראל והמשפטים, ללא הערכה נורמטיבית או המלצות.

***

## חלק א': מידול שימוש סטודנטים ב‑AI (הליבה)

### 1.1 סיווג Use Cases – לפי משימה, רמת מעורבות, וכלי

#### 1.1.1 לפי סוג משימה אקדמית

הטבלה הבאה ממפה שימושים טיפוסיים של סטודנטים בכלי AI לפי סוג המשימה האקדמית. השורות מתבססות על סקרים גלובליים (DEC, Chegg, HEPI), דו"חות שימוש במערכות כמו Claude, ומחקרים איכותניים.[^11][^3][^1]


| משימה אקדמית | דוגמאות לשימוש ב‑AI בפועל | מאפיינים בולטים / ממצאים |
| :-- | :-- | :-- |
| **הכנה לשיעור** | ניסוח שאלות להבנת סילבוס; בקשה להסבר מקדים לנושא לפני שיעור; בניית רשימת מושגים מרכזיים לשיעור הבא[^1][^3] | הרבה שימוש כ"טוטור אישי" לשאלות נקודתיות לפני שיעור, במיוחד במקצועות כמותיים ומשפט חוקתי/מיסים[^11][^12] |
| **קריאת חומרים** | סיכום מאמרים ופרקים; הפקת Abstract בשפה פשוטה; פירוק פסקי דין לחלקים (רקע, שאלה משפטית, נימוקים, הלכה); בקשה להסבר של מונחים לטיניים/דוקטרינריים[^11][^3][^12] | AI משמש כשכבת תיווך בין טקסטים מורכבים לבין הסטודנט, כולל משפטים ארוכים ושפה מקצועית; שימוש נפוץ במשפטים, רפואה והנדסה[^11][^13][^12] |
| **כתיבת עבודות (Humanities / Law / Social Sciences)** | יצירת outline; סיעור מוחות לרעיונות; ניסוח תזה נגדית; שכתוב לשפה "אקדמית"; הגהה תחבירית; ניסוח מבוא/סיכום ראשוני; ניסוח counter‑arguments לטיעון המשפטי או התאורטי[^3][^6] | בסקר HEPI 2025 "יצירת טקסט" היא סיבת השימוש הנפוצה ביותר, לפני עריכה וקריאת ספרי לימוד[^3]. חלק מהסטודנטים מדווחים על שימוש לטיוטה ראשונית, אחרים לעריכה בלבד[^1][^3]. |
| **פתרון תרגילים (מתמטיקה, סטטיסטיקה, קורסי שיטות משפט ו"Legal Problem Solving")** | פתרון בעיות עם הסבר שלבי; בדיקת פתרונות שהסטודנט כבר ניסה; בקשה לרמז במקום פתרון מלא; ניסוח טיעונים חלופיים בפועל "problem question" במשפטים[^11][^14][^12] | Anthropic דיווחה על שימוש רב ב‑Claude לפתרון בעיות צעד‑אחר‑צעד במדעי הטבע ומתמטיקה, ולעבודה שיתופית בבעיות הנדסיות ומשפטיות[^11]. חלק מהסטודנטים משתמשים ב‑AI כ"בודק תשובות" בלבד. |
| **הכנה לבחינות** | יצירת כרטיסיות (flashcards); הפקת שאלות חזרה; ניסוח שאלות רב‑ברירה וניסוח תשובות לדוגמה; סיכום/טבלת הלכות בבחינות במשפטים; סימולציות של שאלות אמריקאיות ב‑bar‑style[^11][^3][^15] | סקרים מראים שסטודנטים רואים ב‑AI "מורה פרטי זמין" לבחינות; שימוש כבד במיוחד בשנים הראשונות של התואר ובמקצועות עם עומס זיכרון רב (משפטים, רפואה)[^11][^13]. |
| **מחקר עצמאי (seminar / capstone / עבודות מחקר)** | הצעת נושאי מחקר; חיפוש ראשוני של כיוונים תאורטיים; זיהוי מילות מפתח; בניית שאלות מחקר; הפקת רשימות מקורות ראשונית (שדורשת בדיקה אנושית); ניסוח פרק שיטת מחקר טיוטאי[^1][^3] | סטודנטים מדווחים על שימוש ב‑AI כדי "להתחיל לזוז" בשלב מוקדם, לפני כניסה לבסיסי נתונים אקדמיים אמיתיים[^1]. בחלק מהמוסדות זה מוגבל במדיניות האקדמית. |
| **פעילות בכיתה / תרגולים** | שימוש ב‑AI כחלק ממשימות מוגדרות: ניתוח תשובות AI, ביקורת על טיעון משפטי שנוצר על‑ידי AI, השוואת תשובת הסטודנט לתשובת המודל[^6][^12] | במחקרים משפטיים ניסיוניים (King’s College London, קורסים בארה"ב) סטודנטים נדרשים לנתח ולהפריך נימוקים משפטיים שנוצרו ב‑GenAI, ולזהות כשלים בציטוטים ובהנמקה[^12][^6]. |
| **חיים אקדמיים "רכים"** | ניסוח מיילים למרצים; כתיבת מכתבי בקשה (extensions); עזרה בכתיבת קורות חיים; ניסוח פוסטים לקבוצות סטודנטים; תרגום הודעות מנהלה[^1][^3] | שימוש זה פחות מדובר במחקרים, אך עולה בסקרים כלליים על תלמידים וסטודנטים (בעיקר לעניין ניסוח, תרגום ושיפור טון)[^1][^16]. |
| **משימות ייחודיות לסטודנטים למשפטים** | סיכום פסקי דין; ניסוח memos; ניסוח טענות בכתב; המרה של lecture notes ל‑issue trees; סימולציית חקירה נגדית; יצירת skeleton arguments; ניסוח חוזים ראשוני עם כלי ייעודי (CoCounsel, Lexis+ AI, Harvey)[^17][^6][^12] | מחקרים מדווחים על שימוש ב‑GenAI עבור: ניסוח טיעונים ראשוניים, שיפור ניסוח IRAC, בדיקת טיעונים נגדיים, ולמידה של סגנון כתיבה משפטי[^6][^12]. במקביל, קיים שימוש בכלים משפטיים ייעודיים המשלבים GenAI במאגרי Lexis / Westlaw[^17][^18]. |

#### 1.1.2 לפי רמת מעורבות ה‑AI בתהליך (0–4)

על בסיס:

- טקסונומיית דפוסי השימוש "Not for Me / Escape / Get Me Going / Feedback Please / Help Me Learn / Magnify",[^19]
- התבוננות בדפוסי עבודה ב‑Claude (Direct / Collaborative Problem Solving / Output Creation),[^11]
- וסקרים איכותניים עם סטודנטים,[^20][^6]

ניתן לתאר רצף מעורבות:


| רמה | תיאור כללי | דוגמאות קונקרטיות |
| :-- | :-- | :-- |
| **0 – אין שימוש ("Not for Me")** | הסטודנט נמנע משימוש בכלי AI, מתוך חוסר עניין, חשש מיושרה אקדמית, תפיסה שזה "לא לגיטימי" או העדפה לעבוד לבד[^19][^7]. | סטודנט למשפטים שמצהיר שאינו משתמש כלל ב‑ChatGPT בגלל חשש לפגיעה ביושרה המקצועית העתידית[^6]; סטודנט במדעי הרוח שמסתפק במילון/Google בלבד. |
| **1 – עזר (Assistant / Get Me Going)** | AI משמש כעוזר נקודתי: הבהרת מושגים, הצעת רעיונות ראשוניים, תרגום, הגהה בסיסית. עיקר העבודה הקוגניטיבית נשאר אצל הסטודנט[^19][^11]. | שימוש ב‑AI ליצירת רשימת רעיונות לנושא עבודה, ואז כתיבה עצמאית; שימוש ב‑Grammarly בלבד לשיפור ניסוח[^1][^3]. |
| **2 – שותף (Partner / Feedback Please / Help Me Learn)** | שיתוף פעולה רציף: שכתוב, קבלת משוב, שיפור ניסוחים, דיאלוג שיטתי על טיעון או פתרון. הסטודנט מנסח גרסאות, AI מגיב, והסטודנט בורר ומתקן[^19][^11][^20]. | סטודנט למשפטים שמעלה טיוטת memo ל‑AI ומבקש ביקורת על מבנה ה‑IRAC והבהרת נימוקים; סטודנט לכלכלה שמנהל "שיחה" עם המודל כדי להבין הוכחה מתמטית[^11][^20]. |
| **3 – מייצר (Generator / Escape)** | AI מייצר טיוטות מלאות של תשובות, סעיפי חוזה, סיכומי מאמרים או מסות, והסטודנט עורך ברמה כזו או אחרת. עיקר ניסוח התוכן הראשוני – לא בידי הסטודנט[^19][^1][^3]. | בקשה מהמודל לנסח "סיכום של פסק דין X באורך 1,000 מילים" ואז עריכת ניסוח; יצירת עבודה סמינריונית ראשונית בעזרת AI ושכתוב חלקי שלה[^21]. |
| **4 – מחליף (Replacer / Automation)** | שימוש ב‑output AI עם שינויים מינימליים, לעיתים ללא קריאה מלאה או ביקורת אנושית. הסטודנט מפקיד בידי ה‑AI כמעט את כל המשימה[^9][^3][^7]. | הדבקת שאלת בחינה לבית/תרגיל לבית במלואה ל‑GenAI והגשת התשובה כמעט "as‑is"; סטודנט שכותב עבודת סמינריון כמעט שלמה באמצעות AI, כפי שתואר בכתבה על סטודנטית שהורחקה על תנאי[^21]. |

המחקרים מראים שרוב הסטודנטים נעים בין רמות 1–3, עם מיעוט שמצהיר על הימנעות מלאה, ומיעוט אחר שמשתמש ברמה 4 – לעיתים גם כשהדבר אסור במדיניות המוסד.[^3][^7][^1]

#### 1.1.3 לפי סוגי כלים

על בסיס סקרים גלובליים (DEC, Chegg, HEPI) וסקרים ייעודיים למשפטים ולמקצועות אחרים:[^17][^2][^22][^11]


| קטגוריית כלי | דוגמאות | שימושים בולטים אצל סטודנטים |
| :-- | :-- | :-- |
| **מודלי שפה כלליים (General‑purpose LLMs)** | ChatGPT (GPT‑4, GPT‑4o), Claude, Gemini, Perplexity[^11][^2] | עיקר השימוש: הסברים, סיכומים, יצירת טקסטים, תרגום, כתיבת קוד, סיעור מוחות, סימולציות שאלות בחינה[^11][^1][^3]. |
| **כלי AI משולבים בפלטפורמות קיימות** | Microsoft Copilot, Google Workspace AI, כלי AI ב‑LMS, תוספים בתוך Word/Docs[^2][^23] | שיפור כתיבה "שקט" (rewrite / tone), הצעות אוטומטיות בעת כתיבה, סיכום מיילים וחומרים; לעיתים הסטודנטים לא מודעים לכך שהם "משתמשים ב‑AI". |
| **כלי כתיבה והגהה ייעודיים** | Grammarly, QuillBot, DeepL Write[^2][^20] | בעיקר שיפור דקדוק, ניסוח, תרגום; שימוש חזק בקרב סטודנטים שאנגלית אינה שפת אם, כולל סטודנטים למשפטים ששפת ההוראה שלהם אנגלית[^20]. |
| **כלים ייעודיים למשפטים** | Lexis+ AI, Westlaw Precision עם CoCounsel, Harvey, Spellbook, Lawdify[^17][^18][^24] | סטודנטים במדינות שבהן לכלים אלה יש רישוי מוסדי משתמשים בהם למחקר משפטי, ניסוח טיוטות חוזים, memos וסיכומי פסיקה; בדגש על פקולטות שעובדות בשיתוף עם לשכות עורכי דין[^17][^18][^25]. |
| **כלי קוד ואנליטיקה** | GitHub Copilot, Claude Code, Jupyter AI | בעיקר אצל סטודנטים למדעי המחשב, הנדסה וכלכלה אמפירית – לכתיבת קוד, ניתוח נתונים, בדיקת תרגילי תכנות[^11]. |
| **צ'טבוטים מוסדיים** | "מרצה וירטואלית" באוניברסיטת תל‑אביב, צ'טבוטים מוסדיים לשירותי מידע[^26][^27] | באוניברסיטת תל‑אביב דווח על אלפי שאלות שהופנו ל"מרצה הווירטואלית" שסייעה לסטודנטים בשאלות על תוכן הקורס, תוך הפניה לדקות המדויקות בהרצאות המוקלטות[^26]. |

### 1.2 נתונים כמותיים מרכזיים על שימוש סטודנטים

הטבלה הבאה מסכמת חלק מהסקרים הבולטים (עולם, ישראל, משפטים):


| מחקר / סקר | מדגם | ממצא מרכזי רלוונטי | שנה | מקור |
| :-- | :-- | :-- | :-- | :-- |
| **Digital Education Council – Global AI Student Survey 2024** | 3,839 סטודנטים (תואר ראשון, שני, דוקטור) ב‑16 מדינות[^2][^1] | 86% משתמשים ב‑AI בלימודים; 24% משתמשים מדי יום; ChatGPT בשימוש אצל 66%; ממוצע 2.1 כלים לסטודנט; 58% מרגישים שחסרות להם מיומנויות AI[^2][^1]. | 2024 | [^2][^1] |
| **Chegg Global Student Survey 2025** | 11,706 סטודנטים לתואר ראשון ב‑15 מדינות[^1] | 80% השתמשו ב‑GenAI לתמיכה בלימודים; 53% מהמשתמשים מודאגים מאי‑דיוקים; הסטודנטים מדווחים על שימוש לסיכומים, רעיונות למחקר ולתמיכה בעבודות[^1]. | 2025 | [^1] |
| **HEPI / Kortext – Student Generative AI Survey 2025 (UK)** | 1,041 סטודנטים לתואר ראשון בבריטניה[^3] | שיעור המשתמשים ב‑GenAI בהערכות עלה מ‑53% ל‑88% תוך שנה; 92% דיווחו על שימוש כלשהו ב‑AI; שימוש נפוץ להסברת מושגים, סיכום מאמרים והצעת רעיונות למחקר; 51% משתמשים בעיקר כדי לחסוך זמן, 50% כדי לשפר איכות עבודה; 53% חוששים שיואשמו בהעתקה; 67% סבורים ששימוש ב‑AI הוא "חיוני" בעולם המודרני; רק 36% קיבלו הכשרה רשמית מהאוניברסיטה[^3]. | 2024–2025 | [^3] |
| **Meta‑summary of AI in Higher Education Surveys** | סינתזה של סקרים רבים 2024–2025[^1] | רוב הסקרים מראים שרוב הסטודנטים (80–90%) משתמשים ב‑AI במידה כלשהי; שיעורי שימוש יומי או שבועי גבוהים; בולט פער בין שימוש סטודנטים לשימוש מרצים; תחושת חוסר מוכנות גבוהה גם אצל סטודנטים וגם אצל סגל[^1]. | 2024–2025 | [^1] |
| **BestColleges 2023 – College Students \& AI** | סטודנטים בארה"ב[^7] | כ‑51% מהסטודנטים סבורים ששימוש ב‑AI הוא סוג של העתקה או פלגיאט, אך חלק ניכר מודה שהוא משתמש בכלים בכל זאת[^7]. | 2023 | [^7] |
| **ChatGPT \& Gen Z – college students** | מדגם סטודנטים לקולג' (מאמר ב‑ScienceDirect)[^14] | 43% מהסטודנטים מדווחים על שימוש בכלים כמו ChatGPT; כחצי מהמשתמשים מסתמכים על הכלים להשלמת פרויקטים ועבודות[^14]. | 2024 | [^14] |
| **Anthropic – How University Students Use Claude** | ניתוח שיחות סטודנטים ב‑Claude.ai לפי תחומים[^11] | זיהוי ארבעה דפוסי אינטראקציה (פתרון בעיות ישיר/שיתופי, יצירת תוצרים ישירה/שיתופית); שימוש עודף של סטודנטים למדעי המחשב (38.6% מהשיחות לעומת 5.4% מחלקם בתארים); מדעי הטבע ומתמטיקה משתמשים ב‑Claude בעיקר לפתרון בעיות, מדעי הרוח יותר לכתיבה וניתוח[^11]. | 2025 | [^11] |
| **LexisNexis – Generative AI \& The Legal Profession (Law Students)** | 1,239 סטודנטים למשפטים בארה"ב, 1,176 עורכי דין, 1,765 צרכנים[^22][^6] | 61% מהעורכים ו‑44% מהסטודנטים למשפטים רואים ב‑GenAI גורם שישנה את לימודי המשפטים; 44% מהסטודנטים למשפטים כבר ניסו GenAI; 9% משתמשים בו בפועל ללימוד, 25% מתכננים להשתמש בו בעתיד; 91% מהסטודנטים מודאגים משאלות אתיות[^22][^6]. | 2023 | [^22][^6] |
| **LexisNexis / LawNext – Law Students Are Reluctant To Use ChatGPT** | סקר סטודנטים למשפטים בארה"ב[^28][^29] | רק 9% מהסטודנטים למשפטים משתמשים ב‑GenAI באופן פעיל ו‑25% מתכננים להשתמש; חששות מרכזיים: אי‑דיוקים, פגיעה ביושרה אקדמית, סודיות לקוחות עתידיים, תפיסת סגל שמדובר ברמאות[^28][^6][^29]. | 2023 | [^28][^6][^29] |
| **ABA Task Force on Law \& AI – AI and Legal Education Survey** | 29 בתי ספר למשפטים בארה"ב (דקנים/מרצים)[^28][^30][^25] | 55% מציעים קורסים ייעודיים ב‑AI, 83% מציעים הזדמנויות קליניות/אחרות ללמוד שימוש בכלי AI, 85% שוקלים שינויי תכנית לימודים; 69% עדכנו את מדיניות היושרה האקדמית בהתייחס ל‑GenAI[^30][^25]. הסקר עוסק בעיקר במוסדות, פחות בדפוסי שימוש סטודנטים. | 2023–2024 | [^30][^25] |
| **ישראל – The Jerusalem Post** | סקר סטודנטים באוניברסיטאות בישראל[^5] | כ‑53% מהסטודנטים דיווחו על שימוש ביישומי AI; 66.5% מהמשתמשים עושים זאת "מפעם לפעם בשבוע"[^5]. | 2023 | [^5] |
| **ישראל – דיווח ישראל היום** | סקר סטודנטים בישראל[^4] | כ‑90% מהסטודנטים השתמשו בכלי AI במהלך הסמסטר האחרון; כ‑60% אינם רואים בתוצרים אמינים מספיק; כ‑50% חוששים שהשימוש ייתפס כרמאות[^4]. | 2025 | [^4] |
| **מחקר איכותני על סטודנטים בישראל** | 50 סטודנטים להשכלה גבוהה בישראל; ראיונות וקבוצות מיקוד[^20] | זוהו שישה נושאים מרכזיים: יעילות וחיסכון בזמן, פרסונליזציה, שיפור הישגים, דאגה לפרטיות, אי‑שוויון בגישה לכלים, חשש מפגיעה בחשיבה ביקורתית. הסטודנטים תיארו יחס חיובי כללי ל‑AI, יחד עם דרישה להנחיות מוסדיות והכשרה רשמית[^20]. | 2025 | [^20] |

### 1.3 מניעים לשימוש – סיווג מניעי הסטודנטים

על בסיס סקרי HEPI, DEC, Chegg, BestColleges, LexisNexis, והמחקר האיכותני בישראל, ניתן לבנות טקסונומיה של מניעים:[^22][^20][^7][^1][^3]

1. **יעילות וחיסכון בזמן**
    - HEPI: 51% מהסטודנטים מציינים שחיסכון זמן הוא הסיבה המרכזית לשימוש ב‑AI.[^3]
    - סטודנטים בישראל מתארים ש‑AI "חוסך זמן ומאפשר להתמקד בעיקר".[^20]
    - במקצועות עם עומס קריאה גבוה (חוק, רפואה) השימוש בסיכומים אוטומטיים וסריקת פסקי דין/מאמרים הופך לכלי מרכזי.[^13][^12][^11]
2. **שיפור איכות התוצר**
    - כ‑50% מהסטודנטים ב‑HEPI מציינים שיפור איכות העבודה כסיבה עיקרית לשימוש.[^3]
    - Grammarly וכלי שכתוב נתפסים כ"עין שנייה" לפני הגשה.[^20]
    - סטודנטים למשפטים משתמשים ב‑GenAI כדי לשפר ניסוח משפטי ולחדד טיעונים, במיוחד בשפה שאינה שפת אם.[^12][^6]
3. **התמודדות עם עומס**
    - סקרים גלובליים מדגישים עומס קורסים ועבודה כמנוע מרכזי לשימוש ב‑AI כ"מאיץ" עבודה.[^1][^3]
    - דפוס "Escape" בטקסונומיית השימוש מתאר שימוש ב‑AI כדי להימנע ממשימות משעממות או שחוזרות על עצמן.[^19]
    - בכתבות ישראליות מתוארת מציאות שבה סטודנטים "התרגלו לכתוב עבודות עם ChatGPT" כחלק מניסיון לעמוד בעומס המטלות.[^31][^32]
4. **פער בהבנת החומר / תמיכה בלמידה**
    - שימוש כ"טוטור אישי" להסבר חוזר של מושגים קשים, לתרגום ולפירוק בעיות מורכבות.[^13][^11][^20]
    - במחקר הישראלי הודגש שימוש ב‑AI להסבר מחדש של מושגים שלא הובנו בהרצאה, עם תחושה שהמידע "נדבק" טוב יותר.[^20]
    - בסקר Pew בקרב בני נוער, רוב המשתמשים רואים שימוש ב‑ChatGPT קודם כל כהזדמנות "ללמוד משהו חדש".[^33]
5. **נורמה חברתית – "כולם עושים את זה"**
    - HEPI מדווח על תפיסה הולכת וגוברת ש‑GenAI הוא חלק "רגיל" מתהליך הלמידה, ושסטודנטים רואים בו "חיוני" בעולם המודרני.[^3]
    - מחקרים מציינים שתלמידים שסביבתם משתמשת ב‑AI נוטים יותר לאמץ אותו, במיוחד באוניברסיטאות טכנולוגיות ובפקולטות להנדסה ומשפטים עם התנסות טכנולוגית גבוהה.[^2][^11]
    - בכתיבה פופולרית על האקדמיה בישראל מדגישים שהסטודנטים כבר משתמשים "במסה קריטית", גם כאשר מדיניות פורמלית עוד מתהווה.[^34][^35][^31]
6. **יתרון תחרותי וחרדת פיגור**
    - חלק מהסטודנטים מדווחים שהם משתמשים ב‑AI מפני שהם חוששים "להישאר מאחור" מול אחרים שמשתמשים.[^1][^3]
    - בסקרים בארה"ב, סטודנטים רבים סבורים ששימוש ב‑AI הוא חיוני כדי לעמוד ברמת התפוקה המצופה בעבודה העתידית.[^16][^1]
7. **תמיכה לשונית ותרבותית**
    - סטודנטים בינלאומיים וסטודנטים בשפה שאינה שפת אם משתמשים ב‑AI לתרגום, שיפור ניסוח, התאמת טון תרבותי של טקסטים ואימיילים.[^1][^20]
8. **סקרנות טכנולוגית וניסוי**
    - בפקולטות עם אוריינטציה טכנולוגית גבוהה (מדעי המחשב, הנדסה, ולעיתים משפטים טכנולוגיים) סטודנטים רואים ב‑AI "מעבדה" להתנסות ולמידת מגבלות המערכות.[^36][^12][^11]

### 1.4 דפוסים ייחודיים לסטודנטים למשפטים

#### 1.4.1 שיעור שימוש ועמדות

מחקרים וסקרים בתחום המשפטים מצביעים על דפוס מעט שונה לעומת אוכלוסיית הסטודנטים הכללית:

- סקר LexisNexis 2023:
    - 44% מסטודנטים למשפטים בארה"ב דיווחו שכבר השתמשו ב‑GenAI כלשהו.[^22]
    - רק 9% ציינו שהם משתמשים בו בפועל לצורך לימודים בזמן אמת, ו‑25% מתכננים לשלב אותו בהמשך.[^6]
    - 91% הביעו חששות אתיים ביחס לשימוש ב‑GenAI.[^22]
- מאמר "Learning the Law with AI: Why Law School Students Are Tentative about Using ChatGPT" מסכם את הסיבות העיקריות להימנעות חלקית:
    - חשש מאי‑דיוקים והמצאות בפסיקה ובחקיקה.
    - חשש מהפרת חובת סודיות מקצועית עתידית.
    - חשש מפגיעה ביושרה האקדמית ומהשלכות משמעתיות.[^28][^29][^6]

כלומר, סטודנטים למשפטים מאמצים את הכלים, אך באופן זהיר, עם מודעות חזקה להשלכות מקצועיות עתידיות.

#### 1.4.2 משימות ייחודיות במשפטים והשימוש ב‑AI

המשימות המשפטיות יוצרות use cases מובחנים:

- **ניתוח פסקי דין**
    - סטודנטים משתמשים ב‑AI כדי:
        - לפרק את פסק הדין לרקע, סוגיה, נימוק והלכה;
        - להפיק תקציר רלוונטי לבחינה;
        - להשוות בין כמה פסקי דין על אותה סוגיה.[^12][^11]
    - מחקרים מדווחים שסטודנטים מזוהים כביקורתיים כלפי סיכומי AI: הם מזהים חוסר דיוק בנימוק, השמטת פסיקה רלוונטית, ושגיאות בציטוט.[^12]
- **כתיבה משפטית (Legal Writing)**
    - AI משמש לשיפור ניסוח IRAC, הצעת מבנה ל‑memo, הגהה, ובניית רשימת counter‑arguments.[^6]
    - מאמרים על הוראת משפט מציינים שסטודנטים משתמשים ב‑AI כעורך לשוני ולוגי, אך לעיתים מפתים אותו לכתוב "חלקים שלמים" של המסמך.[^6]
- **Legal Research**
    - סטודנטים משתמשים הן ב‑LLMs כלליים והן בכלים ייעודיים (Lexis+ AI, CoCounsel, Harvey) לחיפוש ראשוני, ניסוח outline למחקר, והפקת memos ראשוניים.[^18][^24][^17]
    - סקרי ABA על פרקטיקה מצביעים על כך שמשרדי עורכי דין מאמצים AI משפטי בעיקר למחקר וניתוח פסיקה, וסטודנטים נחשפים לכלים אלה דרך הקליניקות והסטאז'.[^30][^17]
- **הכנה לבחינות ול‑bar**
    - שימוש ב‑GenAI כדי לייצר שאלות בחינה בסגנון bar exam ולתרגל ניסוח מסגרות תשובה.[^15]
    - ניסוי באוניברסיטת מינסוטה הראה ש‑ChatGPT יכול להיבחן במבחני משפט ולקבל ציוני עובר (C+), מה שמחדד את הפוטנציאל של AI לבצע חלק ממשימות הבחינה המסורתיות.[^37]


#### 1.4.3 אתגרים ספציפיים למשפטים

- **ציטוט ואסמכתאות**
    - מחקרים מדווחים על בעיות חמורות של "הלכות מומצאות" וציטוטים שגויים במסמכים משפטיים שנוצרו ב‑GenAI.[^12][^6]
    - סטודנטים נדרשים ללמוד להצליב כל ציטוט עם מאגרי Lexis / Westlaw במקום להסתמך על ה‑AI.
- **סודיות וחיסיון**
    - במקצוע המשפטים יש רגישות גבוהה לחשיפת פרטי לקוח; ישנה מודעות מוקדמת בקרב סטודנטים לחשש משימוש ב‑AI בענייני לקוח עתידיים ללא בקרות.[^24][^17][^6]
- **קונפליקט בין מודל הערכה מסורתי ל‑GenAI**
    - מאמרים על הוראת כתיבה משפטית מציינים שהסתמכות על עבודות כתובות כמדד כמעט יחיד לכישורי הסטודנט אינה תואמת לעידן GenAI, מאחר שניתן לכתוב טיוטות איכותיות מאוד בעזרת AI.[^6]

בסיכום חלק זה: סטודנטים למשפטים עושים שימוש בפונקציות דומות לסטודנטים אחרים (סיכום, ניסוח, הסברים, רעיונות), אך במסגרת משימות משפטיות מובְנות יותר ובעוצמת חשש אתית גבוהה יותר.

***

## חלק ב': מיפוי המצב בעולם

### 2.1 מחקרים אמפיריים על שימוש סטודנטים ב‑AI

ניתן לזהות כמה קבוצות מחקרים:

1. **סקרי שימוש רחבים ורב‑מדינתיים**
    - DEC Global AI Student Survey – כבר הוזכר (86% שימוש; 24% יומי).[^2][^1]
    - Chegg Global Student Survey – 80% שימוש ב‑GenAI; דגש על דיון במתח בין שימוש רחב לבין חוסר אמון בדיוק האינפורמציה.[^1]
    - HEPI / Kortext – מדגם בריטי שמראה זינוק משנה לשנה, שימוש כמעט אוניברסלי, והכרה של סטודנטים בכך ש‑AI משנה גם את צורת ההערכה.[^3]
2. **מחקרים תחומיים ספציפיים**
    - **מדעי המחשב והנדסה:** ניתוח לוגים של צ'טבוטים וקורסי תכנות מראה שימוש אינטנסיבי ב‑GenAI בדיבוג, יצירת קוד ואופטימיזציה.[^38][^11]
    - **מדעי הרפואה:** מחקר על סטודנטים לרפואה בצפון אמריקה מצא מודעות גבוהה ל‑ChatGPT ושימוש לצורך הכנה לבחינות, אך גם חששות חזקים מאי‑דיוקים והשלכות מקצועיות.[^13]
    - **משפטים:** עבודות כמו "ChatGPT Goes to Law School" אינן בוחנות שימוש סטודנטים אלא ביצועי המודל בבחינות, אך הן מדגישות ש‑LLMs יכולים להפיק תשובות ברמת C+ בפקולטות מובילות. מחקרי התערבות (כמו "Testing the Frontier" בקינגס קולג' לונדון) מתמקדים בבדיקת היכולת של סטודנטים לזהות מגבלות של תוכן משפטי שנוצר ב‑AI.[^37][^12]
3. **מחקרי עומק איכותניים**
    - מחקרי ראיונות וקבוצות מיקוד במדינות שונות (כמו המחקר הישראלי שצוטט לעיל) מצביעים על חוויית שימוש חיובית ברובה, אך עם מתח סביב פרטיות, אי‑שוויון, והחשש מאובדן חשיבה ביקורתית.[^34][^20]
4. **טקסונומיות התנהגות שימוש ב‑AI**
    - מחקר "A Taxonomy of Generative AI Use for Course‑Related Independent Learning" הגדיר שישה דפוסי שימוש לאורך רצף abstinence–amplification: Not for Me, Escape, Get Me Going, Feedback Please, Help Me Learn, Magnify.[^19]
    - Anthropic אפיינה ארבעה דפוסי אינטראקציה (פתרון בעיות ישיר/שיתופי, יצירת תוצרים ישירה/שיתופית) המופיעים בכל הדיסציפלינות, אך בעוצמות שונות לפי תחום.[^11]

### 2.2 מדיניות מוסדות – דוגמאות נבחרות (תיאור בלבד)

טבלה חלקית המתמקדת במוסדות שביקשת:


| מוסד | מדינה | מאפייני מדיניות סטודנטים ב‑GenAI (תיאור עובדתי) |
| :-- | :-- | :-- |
| **Harvard (College / University level)** | ארה"ב | האוניברסיטה פרסמה "Guidelines for Using ChatGPT and other Generative AI tools" המתמקדות באבטחת מידע, יושרה אקדמית וזכויות יוצרים; המדיניות הכללית משאירה לקורסים בודדים להגדיר במדויק מה מותר ואסור, תוך עידוד ניסוח מדיניות ספציפית לסילבוס[^39][^40][^41]. כתיבה ענפה מצד סטודנטים ומרצים מתארת מציאות של קורסים רבים שבהם נכתב מפורשות ש"שימוש ב‑AI בעבודות אסור ויביא לכישלון בקורס", לצד קורסים אחרים המתירים שימוש מוגבל עם גילוי נאות[^8][^41]. |
| **Harvard Law School (מדיניות חלקית דרך קורסים וקליניקות)** | ארה"ב | אין מדיניות פקולטאית פומבית אחידה; דוגמאות מסילבוסים (למשל בקליניקות Stanford אבל בתפיסה דומה) מראות מגמה שכיחָה: שימוש ב‑AI בעבודת קליניקה אסור כברירת מחדל, אלא אם ניתן אישור מפורש מהמנחים, בשל אחריות מקצועית ואיסורי גילוי סודות[^42]. ב‑Harvard עצמה, דיונים ב‑Berkman Klein וב‑metaLAB ממליצים על מדיניות קורס‑ספציפית, לא איסור גורף[^41][^43]. |
| **Stanford Law School** | ארה"ב | מדיניות רשמית של הקליניקות: "כברירת מחדל אין להשתמש ב‑ChatGPT או בכלי GenAI אחרים במשימות קליניות"; כל שימוש מחייב אישור מפורש של המנחים, בדגש על איכות מקצועית וחובות אתיות[^42]. ברמת האוניברסיטה פורסמה הנחיה לגבי GenAI וה‑Honor Code, שלפיה שימוש ללא היתר מפורש בבחינות ועבודות נחשב הפרת קוד כבוד, אך מרצים יכולים לאפשר שימוש בפורמט מוגדר[^44]. |
| **University of Oxford** | בריטניה | האוניברסיטה פרסמה מדיניות רשמית לגבי שימוש ב‑AI בהערכה מסכמת: ברירת המחדל – כל שימוש ב‑AI בעבודות ובבחינות אסור, אלא אם צוין אחרת בכתב; שימוש מותר מחייב הצהרה מפורשת על השימוש; שימוש לא מורשה מוגדר כהפרת כללי פלגיאט ועשוי להוביל לכישלון ואף הרחקה[^45][^46][^47]. במקביל, האוניברסיטה אימצה את עקרונות קבוצת ראסל לתמיכה ב‑AI לימודי כאשר הוא משולב באופן אחראי[^48][^46]. |
| **Oxford – Law Faculty (הקשר רחב)** | בריטניה | בהיעדר מסמך פקולטאי עצמאי, הפקולטה כפופה למדיניות האוניברסיטה; ישנם קורסים בודדים שבהם המרצה מציין שימוש מותר לצורך סיכום וניתוח טקסטים, אך ברמת הערכה מסכמת, שימוש ב‑AI נותר מוגבל כשאינו מאושר במפורש[^46][^47]. |
| **University of Melbourne / Melbourne Law School** | אוסטרליה | האוניברסיטה פרסמה מדיניות אקדמית שלפיה שימוש ב‑GenAI כדי להפיק עבודה המוגשת כהישג אישי מהווה לכאורה פגיעה ביושרה אקדמית, אלא אם הותר במפורש והוצהר בהתאם; הסטודנטים נדרשים לציין שימוש ב‑AI בעבודות[^36][^49][^50]. במקביל, האוניברסיטה רואה ב‑GenAI הזדמנות, מפעילה כלי פנימי (Spark AI) ונוקטת גישה מערכתית להכשרת סגל וסטודנטים, תוך התאמת דרכי הערכה[^36][^51][^52][^53]. במסמכים לפרלמנט האוסטרלי נכתב כי במלבורן Law School נעשה כבר שימוש ב‑ChatGPT כדרך לעודד סטודנטים לשקף על סגנון כתיבה, מיומנויות נימוק ושימוש בפסיקה[^36]. |

המכנה המשותף: ברוב המוסדות אין "איסור גורף עולמי", אלא מסגרות כלל‑אוניברסיטאיות שמדגישות אחריות, יושרה והצהרה, עם מרחב למרצים ופקולטות לקבוע מדיניות ספציפית לקורס.

### 2.3 עמדות גופים מקצועיים

#### American Bar Association (ABA)

- **AI and Legal Education Survey (Task Force on Law \& AI)** – דיברנו עליו: מדגיש שמוסדות משפטיים כבר משלבים קורסים ייעודיים ב‑AI, קליניקות וסדנאות, וששינוי תוכניות הלימוד מתרחש במהירות.[^54][^25][^30]
- **דו"חות על פרקטיקה משפטית** – סקרי ABA Legal Technology מדווחים על גידול חד בשימוש ב‑AI בקרב משרדי עורכי דין (מ‑11% ב‑2023 ל‑30% ב‑2024), בדגש על מחקר משפטי וניתוח נתונים, כאשר האחריות המקצועית נשארת אצל עורך הדין.[^17]
- **הנחיות לשימוש AI בבתי משפט** – קבוצת עבודה של ה‑ABA פרסמה עקרונות לשימוש אחראי ב‑AI בבתי המשפט, המדגישים סיכון ל"automation bias" ואת החובה לשמור על שיקול דעת אנושי ועצמאות שיפוטית.[^55]


#### Law Society (UK ומדינות נוספות) ו‑SRA

- **Law Society of England \& Wales** – מפרסמת מסמכים כגון "Generative AI – the essentials", המגדירים את הסיכונים וההזדמנויות של GenAI לפרקטיקה המשפטית, לצד התייחסות לחובות מקצועיות (סודיות, מיומנות, אמון הציבור).[^56][^57]
- **Solicitors Regulation Authority (SRA)** – מפרסמת דו"חות Risk Outlook ואומרת במפורש שאימוץ AI אינו פוטר מחובות מקצועיות, ושעורך הדין נושא באחריות מלאה גם כאשר הוא נעזר בכלים טכנולוגיים; היא מעודדת חדשנות אך דורשת פיקוח, כשירות ואחריות.[^58][^59][^60]


#### גופים מקצועיים אחרים

- **Law Societies בקנדה, אירלנד, ניו‑זילנד** – פרסמו מדריכים לשימוש ב‑GenAI המדגישים: איכות, סודיות, אבטחת מידע ואיסור הסתמכות עיוורת על תוצרי AI ללא אימות.[^61][^62][^63]

עבור סטודנטים למשפטים, עמדות אלה מהוות הקשר: הם לומדים במערכת שמשדרת מצד אחד אימוץ מתגבר של AI בפרקטיקה, ומצד שני דרישה גבוהה לשיקול דעת, אימות, והימנעות מהסתמכות בלעדית על Generative AI.

***

## חלק ג': המצב בישראל

### 3.1 מדיניות מוסדית – ישראל

#### מועצה להשכלה גבוהה (מל"ג) וות"ת

- המסמכים הרשמיים של מל"ג וות"ת עוסקים בשנים האחרונות בעיקר בהיבטי מדיניות לאומיים של בינה מלאכותית (תוכנית לאומית לבינה מלאכותית ומדעי הנתונים, השקעה במחקר, תשתיות, הכשרת הון אנושי).[^64][^65][^66]
- דוחות מבקר המדינה על איכות ההוראה בהשכלה הגבוהה ועל היערכות לאומית ל‑AI מתארים את GenAI כגורם שמערער מודלים מסורתיים של הוראה מבוססת שינון ושליפה, אך אינם מציגים מדיניות אופרטיבית ספציפית לגבי שימוש סטודנטים בכלי GenAI.[^67][^64]

כלומר, ברמת הרגולטור הלאומי אין (נכון לעכשיו) מסמך פומבי מפורט שמגדיר באופן ישיר מה מותר ואסור לסטודנטים בהקשר GenAI; המדיניות נשארת ברובה ברמת המוסדות.

#### דוגמאות ממוסדות אקדמיים בישראל

1. **אוניברסיטת תל‑אביב**
    - פרסמה מסמכים כגון "מדיניות שימוש בכלי AI" ו‑"הטמעת בינה מלאכותית יוצרת בהוראה באקדמיה" המציגים את כלי ה‑GenAI כהזדמנות לתמיכה ולהתייעלות, ומדגישים שימוש מושכל, אחראי ואתי לצורך מחקר, הוראה ולמידה.[^68][^69][^70]
    - האוניברסיטה מפתחת כלים פנימיים כגון "המרצה הווירטואלית" – מערכת AI שמבוססת על חומרי הקורס בלבד, מאפשרת לסטודנטים לשאול שאלות על התוכן המוקלט ולהפנות אותם לדקות הרלוונטיות בהרצאה; ניתוח הפיילוט הראה אלפי שאלות ושביעות רצון גבוהה של הסטודנטים, עם השפעה על מוכנות לשיעור.[^26]
    - במדיניות ה‑GenAI מצוין (לפי מסמך בר‑אילן המצוטט במאמר סקירה) שאין כוונה לאסור שימוש מוחלט, אלא "להתוות את מאפייניו של השימוש הראוי", כאשר לכל מרצה ניתנת סמכות לקבוע את רמת ההיתר בקורס, ודרישה להצהרת סטודנט על שימוש בכלי AI ותיאור תרומתם.[^27][^70]
2. **אוניברסיטת בר‑אילן**
    - לפי דיווח בעיתונות, האוניברסיטה הפיצה מסמך הנחיות המכיר בכך ש"אין מנוס מהצטרפות" לשימוש בבינה מלאכותית, ומתיר לסטודנטים להשתמש בכלי GenAI בעבודות, כל עוד הם מצהירים על כך ומפרטים את תרומת הכלי לתוצר; המרצה רשאי לאסור שימוש בקורס ספציפי, ואם לא הורה אחרת – השימוש מותר בכפוף לדיווח.[^27]
    - המסמך מדגיש את הצורך לעדכן כללי יושרה אקדמית בסביבה עתירת GenAI, ולחדד נהלים לגבי שימוש בבחינות בית ועבודות סמינריוניות.[^27]
3. **מוסדות נוספים**
    - כתבות וראיונות מתארים אימוץ הולך וגדל של AI במכללות טכנולוגיות ובאוניברסיטאות מחקר, גם ברמת לימודי חוץ והנדסה, עם התמקדות בהכנת "דור מהנדסי ה‑AI הבא".[^71]
    - באוניברסיטת רייכמן מוצגים קורסים שבהם סטודנטים נדרשים להשתמש ב‑GenAI כחלק מתהליך פיתוח מוצר, מחקר משתמשים וסימולציות, למשל בקורס AI Product Sprint המשלב מחקר עם פרסונות סינתטיות ו‑low‑code.[^72]

לגבי פקולטות למשפטים בישראל – קשה למצוא בשלב זה מסמכים פומביים מפורטים לגבי מדיניות AI ברמת הפקולטה, אך הדיון הציבורי (לרבות כתבות על מקרים של סטודנטים שהגישו עבודות המבוססות כמעט לחלוטין על GenAI) מראה שמוסדות מתמודדים בפועל עם תופעת השימוש הרחב ומנסים להתאים את נהלי המשמעת.[^21][^31]

### 3.2 דיון ציבורי ואקדמי בישראל

- מאמרים בעברית (למשל במכון ברוקדייל/מכון אדמונד דה רוטשילד בשיתוף Minerva) מציגים גישה שלפיה השימוש ב‑GenAI באקדמיה הוא "הכרחי" וכי יש להתמקד בהטמעה מושכלת, פיתוח פרקטיקות הוראה והערכה מותאמות ובניית אוריינות AI לסטודנטים.[^34]
- כתבות בכלכליסט, מעריב ו‑ynet מצביעות על:
    - שימוש רחב של סטודנטים בכל הפקולטות,
    - חשש של מרצים מהעתקות והיעלמות היכולת להבחין במיומנות האמיתית של הסטודנט,
    - דיון בשאלה האם מודל הבחינות והעבודות הנוכחי מתאים לעידן שבו GenAI מסוגל לייצר תשובות מלאות ברמת איכות גבוהה.[^35][^73][^31]
- המחקר האיכותני על סטודנטים בישראל נותן קול לסטודנטים עצמם, המדווחים על תחושה ש‑AI "משנה את הכללים", יחד עם ציפייה שהמוסדות יספקו הנחיות, הכשרה ואמצעים להבטיח שימוש הוגן ושוויוני.[^20]


### 3.3 פערי מידע לגבי ישראל

הפערים העיקריים:

- אין בשלב זה סקר כמותי ארצי מקיף ומקצועי על דפוסי שימוש סטודנטים ישראלים ב‑GenAI לפי תחום לימוד, שנת לימודים וסוג משימה; הנתונים הקיימים (53%, 90%) מבוססים על סקרי מדיה שאינם שקופים לחלוטין מבחינת מתודולוגיה.[^5][^4]
- חסרה תמונה מסודרת על מדיניות פקולטות למשפטים בישראל: אילו שימושים מותרים בעבודות, באילו קורסים, והאם קיימות הנחיות כתובות פומביות.
- כמעט ואין מחקר אמפירי פומבי המתייחס ספציפית לסטודנטים למשפטים בישראל (בניגוד למחקר כללי על סטודנטים להשכלה גבוהה).[^20]

***

## חלק ד': ניתוח פערים בין בעלי עניין

### 4.1 פער סטודנטים–מרצים

ניתן לתאר את הפער בכמה ממדים:


| ממד | סטודנטים – דפוס מצטייר | מרצים / מוסדות – דפוס מצטייר | הפער |
| :-- | :-- | :-- | :-- |
| **תפיסת היקף השימוש** | סקרים גלובליים מצביעים על 80–90% שימוש; בישראל דווח על 53% עד 90% שימוש[^1][^3][^5][^4]. | סקרים בקרב ראשי מוסדות וסגל דווחו כי "מרבית הסטודנטים משתמשים", אך עם חוסר ידע מפורט איך ובאילו כלים; גורמים מוסדיים רבים מופתעים מעוצמת החדירה של הכלים[^1][^74]. | המרצים לעיתים מעריכים חסר את נפח השימוש, או מניחים שסטודנטים ישתמשו רק במסגרת המותרת; בפועל, הנתונים מצביעים על שימוש נרחב גם במקרים שהמדיניות מגבילה. |
| **הבנת יכולות הכלים** | סטודנטים חווים את הכלים כיעילים וחוסכי זמן, אך גם מודעים במידה מסוימת לבעיות דיוק; ב‑Chegg ו‑HEPI חלק גדול מהסטודנטים מציין חשש מטעות ומ"הזיות", אך בכל זאת משתמש[^1][^3]. | חלק ניכר מהסגל מדווח שאינו מיומן בכלי AI, מרגיש בתחילת הדרך מבחינת אוריינות AI, ולעיתים תופס את הכלי בעיקר כסיכון ליושרה אקדמית ולא כאמצעי פדגוגי[^1][^10][^75]. | סטודנטים לעיתים משתמשים בכלים באופן "עשיר" יותר מהמרצים – למשל, שילוב של סיעור מוחות, עריכה, סימולציה של בחינות – בעוד שמרצים אינם מכירים היטב את האפשרויות ולכן גם מתקשים לתכנן הוראה והערכה מתאימות. |
| **ציפיות ממשימות אקדמיות** | עבור חלק מהסטודנטים, השימוש ב‑AI להפחתת "עבודת low‑level" נתפס כחלק הגיוני מעולם שבו גם המעסיקים יצפו ליכולת עבודה עם AI[^1][^3][^34]. | מרצים רבים עדיין משייכים יכולות כמו ניסוח ראשון של טקסט, כתיבת ניתוח משפטי ראשוני או סיכום מאמר למשימות "ליבה" שיש לבצע ללא סיוע AI, במיוחד בשנים הראשונות[^6][^34]. | פער בהסכמה מה נחשב "מטלה ליבה אנושית" ומה ניתן להעביר ל‑AI. זה בולט במיוחד במשפטים, שבהם מרצים רוצים שסטודנטים יתרגלו כתיבה משפטית מלאה, בעוד שחלק מהסטודנטים רואים ב‑AI "כלי עבודה מקצועי לגיטימי" לפרקטיקה עתידית. |
| **תפיסות יושרה אקדמית** | סקרים מצביעים על כך שחלק גדול מהסטודנטים רואה שימוש ב‑AI כהמשך טבעי לשימוש בבודקי דקדוק, מנועי חיפוש וכד', ואינו תופס כל שימוש כ"רמאות", במיוחד ברמות 1–2 של מעורבות[^7][^3]. | חלק מהמוסדות מיישמים הגדרות נוקשות, שלפיהן כל שימוש ב‑GenAI בהערכה מסכמת ללא היתר ספציפי נחשב פלגיאט (למשל, אוקספורד)[^46][^45]; גם בארה"ב מדיניות רבות מניחות "איסור כברירת מחדל" אלא אם המרצה מתיר אחרת[^76][^44]. | הפער קשור לשאלות טרמינולוגיות (מהי "עזרה מותרת" לעומת "הפקת תוכן"), להבדלים בין מדיניות המוסד להגדרות הסטודנטים עצמם, ולפערים במודעות לכללים. |

### 4.2 פער מדיניות–פרקטיקה

- **עולם:**
    - מוסדות מובילים (אוקספורד, Northwestern Law, Fordham Law) מפרסמים מדיניות קשיחה יחסית לגבי בחינות ועבודות (איסור או הגבלה חמורה), אך סקרים מראים שרוב הסטודנטים משתמשים בכל זאת בכלים בשלב ההכנה, ובהרבה מקרים גם בטיוטות ראשוניות לעבודות.[^76][^46][^3]
    - HEPI: רק 29% מהסטודנטים מרגישים שהמוסד "מעודד" שימוש ב‑AI, למרות ש‑92% כבר משתמשים; רבים מדווחים על "מסרים מעורבים" – מצד אחד דיבור על "הכנה לעולם עתידי עם AI", ומצד שני אזהרות חמורות על יושרה.[^3]
- **ישראל:**
    - באוניברסיטאות כמו בר‑אילן ותל‑אביב יש כבר הנחיות המתירות שימוש בפועל (בהינתן הצהרה וגילוי), אך חלק מהמרצים עדיין מציינים בסילבוסים איסורים גורפים או שאינם מתייחסים כלל לנושא, מה שמוביל ל"ואקום נורמטיבי" והחלטות עצמאיות של סטודנטים.[^69][^70][^34][^27]
    - דיווחים על מקרים שבהם סטודנטים כתבו עבודות סמינריוניות שלמות בעזרת GenAI והועמדו לדין משמעתי מצביעים על כך שהפער בין הצהרות לסטודנטים לבין מעקב ואכיפה עודנו גדול.[^31][^21]


### 4.3 פערי ידע – מה המרצים יודעים / לא יודעים על שימוש סטודנטים

- **מה ידוע (מתוך סקרים וסדנאות סגל)**
    - מרבית מנהלי מוסדות וסגל בכיר מודעים לכך שרוב הסטודנטים משתמשים ב‑AI במידה מסוימת.[^74][^1]
    - חלק ניכר מהמרצים מבינים את הסיכון ל"העתקה" של טקסטים, אך פחות מודעים לדפוסי שימוש ברמות 1–2 (סיעור מוחות, הסבר, ביקורת).[^34][^1]
- **מה פחות ידוע**
    - אילו משימות בדיוק סטודנטים "מאצילים" ל‑AI בכל דיסציפלינה.
    - באיזו מידה סטודנטים מבצעים הערכה ביקורתית של התוצר (Discernment) ולא רק משתמשים בו כ"אמת" זמינה.[^10][^9][^20]
    - כיצד השימוש משתנה בין שנה א' לשנים מתקדמות ובין סטודנטים חזקים לחלשים – למשל, האם סטודנטים חלשים יותר נשענים יותר על רמות 3–4 (Generator/Replacer).[^11][^6]
- **פער בתפיסת סיכון מול פוטנציאל**
    - סגל רבות תופסות את GenAI בעיקר כאיום על הערכה וציון, בעוד שסטודנטים רואים בו גם "תמיכה בלמידה" ו"מאיץ להבין חומר" – במיוחד בישראל, שם סטודנטים מדווחים על שיפור בחוויית הלמידה כאשר האלגוריתם מסביר להם מושגים בקצב שלהם.[^34][^20]

***

## חלק ה': מסגרות ניתוח קיימות

### 5.1 מסגרת ה‑4D (AI Fluency Framework)

מסגרת ה‑4D פותחה כמודל לאוריינות AI ומזוהה במסמכים שונים כ‑Delegation, Description, Discernment, Diligence. היא משמשת גם במוסדות להשכלה גבוהה כדי ללמד סטודנטים כיצד לעבוד עם AI באופן מודע.[^77][^78][^9][^10]

ניתן ליישם אותה לניתוח דפוסי שימוש סטודנטים כדלקמן:


| ציר 4D | שאלה מרכזית | יישום לניתוח דפוסי השימוש של סטודנטים |
| :-- | :-- | :-- |
| **Delegation – האצלת משימות** | מה "מואצל" ל‑AI ומה נשאר אצל הסטודנט? | ניתן למפות use cases לפי סוג המשימה שהסטודנט מעביר ל‑AI: סיכום טקסט, ניסוח outline, כתיבת טיוטה, בדיקת דקדוק, הצעת טיעוני נגד, ניסוח פסקה משפטית. ברמות 1–2 ההאצלה חלקית (רעיונות, ניסוח מחדש), וברמות 3–4 AI מבצע חלק גדול מהמשימה. מיפוי זה מאפשר לזהות באילו נקודות בתהליך הלמידה נעשית "העברת אחריות" חדה ל‑AI[^19][^11][^3]. |
| **Description – תיאור / פרומפטינג** | כיצד סטודנטים מתארים ל‑AI את המשימה ואת מטרת הלמידה? | איכות הפרומפטים משקפת את היכולת המטה‑קוגניטיבית של הסטודנט: האם הוא מגדיר את סוג הטקסט (למשל "memo משפטי בסגנון X"), את הקהל, את רמת הפירוט? במחקרים על סטודנטים להנדסה ולמשפטים נראה שסטודנטים בעלי ניסיון טכנולוגי גבוה יותר כותבים פרומפטים מורכבים יותר ומפיקים תוצרים מדויקים יותר[^38][^11][^36]. אפשר לסווג דפוסי שימוש לפי מורכבות התיאור שהסטודנט נותן ל‑AI. |
| **Discernment – הבחנה וביקורת** | האם הסטודנט מעריך באופן ביקורתי את תוצר ה‑AI? | מחקרים משפטיים (King’s College London, ניסויי קליניקות) מראים שסטודנטים מסוגלים לזהות כשלים ניכרים בתוצרי AI (למשל ניתוח משפטי שטחי, ציטוטי פסיקה שגויים)[^12]. מחקרים כלליים יותר מדווחים על חשש של סטודנטים מאי‑דיוקים, אך גם על נטייה להסתמך חלקית על התוצר ללא הצלבה מלאה[^1][^3][^20]. מימד זה מאפשר לסווג דפוסי שימוש לפי רמת הביקורתיות: ממי שמקבל את התוצר כמות שהוא, ועד למי שמשתמש בו כבסיס להשוואה ולשיפור. |
| **Diligence – אחריות ומסירה** | מי אחראי על התוצר הסופי, ואיך הסטודנט משקף את השימוש ב‑AI? | חלק מהמדיניות המוסדיות (אוקספורד, בר‑אילן, תל‑אביב) מחייבות הצהרה על שימוש ב‑AI[^46][^27][^70]. במציאות, חלק מהסטודנטים מצהירים וחלק לא, גם כאשר השתמשו ברמה גבוהה. מימד זה בוחן האם הסטודנט רואה בעצמו אחראי לבדוק, לצטט ולשאת באחריות לתוצאה – או האם הוא "מוסר" את האחריות ל‑AI. ניתן למפות הבדלים בין תחומים (למשל מדעי המחשב לעומת משפטים) ובין מוסדות שבהם נדרשת הצהרה לעומת כאלה שלא. |

באמצעות ה‑4D ניתן לבנות מודל תיאורי שבו:

- על ציר אחד – סוג המשימה (חלק א' לעיל).
- על ציר שני – רמת ההאצלה (0–4).
- על ציר שלישי – רמת ה‑Discernment וה‑Diligence (האם התוצר נבדק, האם נעשה גילוי נאות).

מודל כזה מאפשר לתאר באופן עשיר ולא דיכוטומי את המציאות: לא "שימוש / אי‑שימוש", אלא מגוון שימושים עם רמות שונות של שליטה אנושית.

### 5.2 מסגרות אחרות – טקסונומיות ו‑frameworks בספרות

מעבר ל‑4D, מופיעים כמה סוגי מסגרות:

1. **טקסונומיות שימוש ב‑GenAI בלמידה**
    - הטקסונומיה של שישה דפוסי שימוש ב‑GenAI בלמידה עצמאית (Not for Me, Escape, Get Me Going, Feedback Please, Help Me Learn, Magnify) מתארת רצף בין הימנעות, שימוש כדי להתחמק ממשימות, שימוש כהנעה, שימוש לצורך משוב, ועד שימוש להעצמת הלמידה.[^19]
    - DEC AI Usage Taxonomy for Higher Education (בתמצית) מציע סיווג של שימושי AI באקדמיה הנע בין "שימוש פתוח", "שימוש עם גילוי", "שימוש עם עמידה בדרישות", "שימוש זהיר" ו"איסור שימוש", ברמת מדיניות מוסדית.[^79][^23]
2. **קטגוריות שימוש GenAI בהערכה (UCL, Universities Reading וכו')**
    - אוניברסיטת UCL והאוניברסיטה של רדינג מציעות מודל של שלוש קטגוריות שימוש ב‑GenAI בהערכה:

3. **אסור** – כאשר GenAI סותר את מטרות הלמידה (למשל בבחינות ידע בסיסי).[^80][^23]
4. **תומך (Assistive)** – כאשר מותר להשתמש ב‑GenAI כעזר (למשל עריכה לשונית, תרגום, משוב), אך לא להפקת התוצר המרכזי.[^80]
5. **אינטגרלי** – כאשר השימוש ב‑GenAI הוא חלק מפורש מן ההערכה והסטודנט נדרש לה demonstate שימוש אחראי בכלי.[^23][^80]
    - מסגרות אלו רלוונטיות במיוחד למשפטים, שבהם ניתן לדמיין קורסים בהם שימוש ב‑GenAI אסור (כתיבה משפטית בסיסית), מותר כתומך (עריכת טקסט) או אינטגרלי (קורס על AI \& Law).
1. **מסגרות המבוססות על Bloom's Taxonomy בעידן AI**
    - מאמרים ועמדות (Oregon State University, The Citadel, OLC) מרחיבים את טקסונומיית בלום כדי לשאול: איזה סוגי עבודה קוגניטיבית אפשר "להוציא" ל‑AI מבלי לפגוע בלמידה, ואילו רמות (הבנה, יישום, אנליזה, הערכה, יצירה) מחייבות עבודה אנושית עצמאית.[^81][^82][^83]
    - במסמכים אלה מוצגים טבלאות המראות, למשל, ש‑AI יכול לעזור בעיקר ברמות נמוכות (זכירה, סיכום) ובחלק מהרמות הגבוהות (יצירת רעיונות), אבל שהערכה ביקורתית מחייבת בקרה אנושית.[^82][^81]
2. **Frameworks מוסדיים לאינטגרציית AI**
    - מסגרות כמו ה‑S.E.C.U.R.E GenAI framework (אוסטרליה) או "AI assessment Venn" (RMIT) מנסות לסווג משימות הערכה לפי רמת סיכון, חשיבות התוצר ודרישות האימות, כדי להחליט איך ולאן AI יכול להשתלב.[^53]
    - מסמך "Introducing a Generative AI Decision Tree for Higher Education" מציע עץ החלטה למרצים ומוסדות לגבי השאלה האם ואיך לשלב GenAI בהוראה ובהערכה, בהתחשב בהיבטים משפטיים, אתיים ופדגוגיים.[^84]
3. **מסגרות למקצוע המשפטי**
    - מדריכים של לשכות עורכי דין (בבריטניה, קנדה, אירלנד, ניו‑זילנד) מסווגים שימושים אפשריים ב‑GenAI לפי תחומים (מחקר משפטי, ניסוח חוזים, סקירת מסמכים, תקשורת עם לקוחות) ולכל אחד מצרפים רשימת סיכונים וחובות מקצועיות (כישורים, סודיות, שקיפות).[^62][^63][^24][^61]
    - מסגרות אלו ניתן לתרגם גם לעולם הסטודנטים למשפטים: איזה שימושים מודגמים ומותרים במהלך הלימודים, ואיזה שימושים מצריכים זהירות מיוחדת כבר בשלב הלימודי.

המסגרות הללו אינן נורמטיביות בהכרח, אלא מספקות כלי תיאורי ומושגי לסיווג דפוסי השימוש, לסימון נקודות סיכון, ולניתוח יחסי הגומלין בין סטודנטים, מרצים וכלים.

***

## נספח: מתודולוגיה, מקורות ופערי מידע

### מתודולוגיית הסקירה

- הסקירה נשענת על:
    - סקרי רוחב גלובליים (DEC, Chegg, HEPI, BestColleges, Pew).[^33][^7][^2][^1][^3]
    - מחקרי עומק ספציפיים (Anthropic על Claude; מחקר איכותני על סטודנטים בהשכלה גבוהה בישראל; מחקרים משפטיים ייעודיים).[^11][^12][^6][^20]
    - מסמכי מדיניות מוסדיים (אוקספורד, הרווארד, סטנפורד, מלבורן, בר‑אילן, תל‑אביב).[^42][^45][^46][^49][^70][^36][^27]
    - מסמכים והנחיות ארגונים מקצועיים (ABA, Law Societies, SRA).[^25][^63][^60][^30][^56][^24]
- המקורות שנבחרו מתמקדים בעיקר בשנים 2023–2025, כאשר GenAI הפך לנגיש לסטודנטים בהיקף נרחב.


### מגבלות ופערי מידע

- אין עדיין סדרת מחקרי אורך (longitudinal) המתארת שינוי בדפוסי השימוש של אותה קוהורט סטודנטים לאורך כל התואר.
- קיים ייצוג יתר למחקרים וסקרים במדינות דוברות אנגלית (ארה"ב, בריטניה, אוסטרליה), ולעומת זאת מעט מחקרים כמותיים באירופה הלא‑אנגלית, אסיה וישראל.[^1][^20]
- במדינת ישראל – יש מחקר איכותני מעמיק אחד לפחות על תפיסות סטודנטים, וסקרים עיתונאיים עם מספרים מרשימים (53%, 90%), אך אין עדיין סקר אקדמי ארצי מפורט לפי תחומים ושנות לימוד.[^4][^5][^20]
- בתחום המשפטים – יש יותר מאמרים תיאורטיים ופדגוגיים על השלכות GenAI, מאשר מחקרים כמותיים שיטתיים על דפוסי שימוש סטודנטים; יוצאי דופן הם סקר LexisNexis ומאמרי סיכום דוגמת "Learning the Law with AI".[^28][^22][^6]

***

## סיכום אינטגרטיבי – תמונת המודל

ניתן לסכם את מודל התופעה כך:

1. **שיעורי השימוש** – ברוב מערכות ההשכלה הגבוהה, ובעיקר בקרב סטודנטים לתואר ראשון, GenAI הפך לכלי שימוש יומיומי או שבועי עבור רוב הסטודנטים. בישראל, אינדיקציות תקשורתיות ואיכותניות מרמזות על שיעורי שימוש מהגבוהים בעולם.[^85][^5][^4]
2. **מפת המשימות** – ה‑use cases נעים מהסברים וסיכומים ועד לכתיבה משפטית מלאה והכנה לבחינות מקצועיות. במשפטים, משימות כמו סיכום פסקי דין, כתיבת memos וניתוח סוגיות – עוברות סיוע משמעותי מ‑AI.[^12][^11][^6]
3. **רמות מעורבות** – סטודנטים ממקמים את עצמם על רצף מ‑0 (הימנעות) עד 4 (החלפה מלאה), עם ריכוז דפוסים ברמות 1–3; חלק מהשימושים (כתיבה מלאה של עבודות) עומדים בסתירה למדיניות רשמית של מוסדות.[^21][^19][^1][^3]
4. **תחום המשפטים** – מתאפיין בשילוב ייחודי של:
    - שימוש בכלים כלליים וייעודיים למשפטים;
    - רמת חשש אתית גבוהה;
    - ותלות באיכות ציטוטים והנמקות, שה‑AI מתקשה לספק באופן עקבי.[^17][^6][^12]
5. **פערי תפיסה ומדיניות** – יש פער בולט בין דפוסי השימוש בפועל לבין מדיניות וחוויית הסגל, הן ברמת העולם והן בישראל. סטודנטים חווים את הכלים כמשאב חיוני, בעוד שמוסדות עדיין מגבשים את מסגרות ההוראה, ההערכה והיושרה האקדמית בהקשר ל‑GenAI.[^34][^1][^3]
6. **מסגרות ניתוח** – מודלים כמו 4D, טקסונומיות שימוש וקטגוריות GenAI בהערכה מספקים שפה תיאורית עשירה לסיווג מעשי הסטודנטים והחלטות המדיניות, מבלי לקבוע מראש מה "נכון" או "לא נכון".[^9][^82][^80][^19]

המסמך כולו מציג אפוא תיאור רב‑שכבתי של התופעה: מעולם → ישראל → משפטים; מהתנהגות סטודנטים → מדיניות מוסדות → ציפיות מקצועיות, תוך שימוש בכלים תיאורטיים כמו 4D ושלל טקסונומיות לצורך מידול ולא לצורך הכרעה נורמטיבית.
<span style="display:none">[^100][^101][^102][^103][^104][^105][^106][^107][^86][^87][^88][^89][^90][^91][^92][^93][^94][^95][^96][^97][^98][^99]</span>

<div align="center">⁂</div>

[^1]: https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/

[^2]: https://campustechnology.com/articles/2024/08/28/survey-86-of-students-already-use-ai-in-their-studies.aspx

[^3]: https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/

[^4]: https://www.israelhayom.co.il/news/education/article/19223815

[^5]: https://www.jpost.com/israel-news/article-733284

[^6]: https://www.legalwritingjournal.org/article/92759-bracing-for-impact-revising-legal-writing-assessments-ahead-of-the-collision-of-generative-ai-and-the-nextgen-bar-exam

[^7]: https://www.bestcolleges.com/research/college-students-ai-tools-survey/

[^8]: https://www.thecrimson.com/article/2025/9/3/siddiqui-harvard-ai-inequitable/

[^9]: https://stars.library.ucf.edu/cgi/viewcontent.cgi?article=1500\&context=teachwithai

[^10]: https://www-cdn.anthropic.com/334975cdec18f744b4fa511dc8518bd8d119d29d.pdf

[^11]: https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude

[^12]: https://lthj.qut.edu.au/article/view/4037

[^13]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11376538/

[^14]: https://www.sciencedirect.com/science/article/pii/S2590291124003607

[^15]: https://www.uow.edu.au/media/2024/what-happens-when-law-students-go-head-to-head-with-genai.php

[^16]: https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/

[^17]: https://www.lawnext.com/2025/03/aba-tech-survey-finds-growing-adoption-of-ai-in-legal-practice-with-efficiency-gains-as-primary-driver.html

[^18]: https://www.thomsonreuters.com/en-us/posts/technology/chatgpt-generative-ai-law-firms-2023/

[^19]: https://sciety-labs.elifesciences.org/articles/by?article_doi=10.35542%2Fosf.io%2Fzebk4_v1

[^20]: https://jier.org/index.php/journal/article/download/3723/2967/6575

[^21]: https://www.mako.co.il/nexter-news/Article-5ee3ff796311a91026.htm

[^22]: https://www.lexisnexis.com/pdf/lexisnexis-legal-ai-sample-report.pdf

[^23]: https://nationalcentreforai.jiscinvolve.org/wp/2024/07/31/navigating-the-future-higher-education-policies-and-guidance-on-generative-ai/

[^24]: https://www.mlaw.gov.sg/files/Guide_for_Using_Generative_AI_in_the_Legal_Sector.pdf

[^25]: https://www.abajournal.com/web/article/artificial-intelligence-is-taking-over-law-schools

[^26]: https://www.ynet.co.il/environment-science/article/hkskvpnwje

[^27]: https://www.amisalant.com/?p=27480

[^28]: https://lawlibguides.luc.edu/GenerativeAI/LawSchool

[^29]: https://www.lawnext.com/2023/06/law-students-are-reluctant-to-use-chatgpt-survey-finds-the-question-is-why.html

[^30]: https://nationaljurist.com/aba-task-force-releases-survey-on-artificial-intelligence-and-legal-education/

[^31]: https://www.maariv.co.il/news/education/article-1252547

[^32]: https://www.maariv.co.il/economy/israel/article-1225615

[^33]: https://www.pewresearch.org/short-reads/2025/01/15/about-a-quarter-of-us-teens-have-used-chatgpt-for-schoolwork-double-the-share-in-2023/

[^34]: https://portal.macam.ac.il/article/shiluv-bina-melachutit-bemosdot/

[^35]: https://www.calcalist.co.il/local_news/article/ryx43vhr1g

[^36]: https://www.aph.gov.au/DocumentStore.ashx?id=f536fcf8-dd6a-4344-b0e5-828660f5e72c\&subId=745265

[^37]: https://collimateur.uqam.ca/wp-content/uploads/sites/11/2023/01/SSRN-id4335905.pdf

[^38]: https://nemo.asee.org/public/conferences/365/papers/48902/download

[^39]: https://www.huit.harvard.edu/ai/guidelines

[^40]: https://provost.harvard.edu/guidelines-using-chatgpt-and-other-generative-ai-tools-harvard

[^41]: https://aicodeofconduct.mlml.io

[^42]: https://law.stanford.edu/juelsgaard-intellectual-property-and-innovation-clinic/clinic-and-law-school-policies-and-syllabus-language/

[^43]: https://cyber.harvard.edu/projects/artificial-intelligence-and-law

[^44]: https://communitystandards.stanford.edu/generative-ai-policy-guidance

[^45]: https://www.ox.ac.uk/students/life/it/guidance-safe-and-responsible-use-gen-ai-tools

[^46]: https://libguides.bodleian.ox.ac.uk/using-ai-to-support-academic-work/university-policies

[^47]: https://www.ctl.ox.ac.uk/ai

[^48]: https://cherwell.org/2024/01/16/oxford-releases-new-guidance-on-ai-use-for-students/

[^49]: https://academicintegrity.unimelb.edu.au/staff-resources/artificial-intelligence/university-policy-and-actions

[^50]: https://msd.unimelb.edu.au/belt/quality/generative-ai/genai-and-student-academic-integrity

[^51]: https://universitas21.com/wp-content/uploads/2025/09/University-of-Melbourne-Case-Study-on-GenAI-July-2025.docx

[^52]: https://msd.unimelb.edu.au/belt/quality/generative-ai

[^53]: https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/gen-ai-knowledge-hub/gen-ai-academic-integrity-and-assessment-reform

[^54]: https://iclr.net/news/american-bar-associations-artificial-intelligence-task-force-releases-law-school-survey/

[^55]: https://www.lawnext.com/2025/02/aba-working-group-publishes-guidelines-for-responsible-ai-use-by-state-and-federal-courts.html

[^56]: https://www.lawsociety.org.uk/topics/ai-and-lawtech/generative-ai-the-essentials

[^57]: https://lawsociety.libguides.com/AI/professional-guidance

[^58]: https://www.conveyancingassociation.org.uk/what-are-the-regulators-saying-about-ai-use-in-law-firms/

[^59]: https://www.legalservicesboard.org.uk/wp-content/uploads/2024/04/Legal-Services-Board-update-on-AI-approach-April-2024-pdf.pdf

[^60]: https://www.sra.org.uk/sra/research-publications/artificial-intelligence-legal-market/

[^61]: https://www.lexisnexis.ca/pdf/2025/legal-brief/issue34-4-artificial-intelligence-practical-guidance.pdf

[^62]: https://www.lawsociety.org.nz/professional-practice/rules-and-maintaining-professional-standards/generative-ai-guidance-for-lawyers/

[^63]: https://www.lawsociety.ie/artificial-intelligence-ai/generative-ai-guidance/

[^64]: https://library.mevaker.gov.il/sites/DigitalLibrary/Documents/2024/2024.11-Cyber/2024.11-Cyber-107-AI.pdf

[^65]: https://che.org.il/decision/השתתפות-ותת-בפעימה-השנייה-של-התכנית-הל/

[^66]: https://che.org.il/הנהלת-מלג-ותת/אסטרטגיה-ובינלאומיות/תכנית-לאומית-בינה-מלאכותית-ומדעי-הנתו/

[^67]: https://library.mevaker.gov.il/sites/DigitalLibrary/Documents/2025/2025-10/2025.10-301-Higher-Education.pdf

[^68]: https://innovative-learning.tau.ac.il/AI_Tools_Usage_Policy

[^69]: https://innovative-learning.m.tau.ac.il/sites/innovative-learning.tau.ac.il/files/media_server/innovative-learning/%D7%A9%D7%99%D7%9E%D7%95%D7%A9%D7%99%20AI%20%D7%91%D7%94%D7%95%D7%A8%D7%90%D7%94%20%D7%95%D7%91%D7%9C%D7%9E%D7%99%D7%93%D7%94/%D7%93%D7%95%D7%97%20%D7%A7%D7%94%D7%99%D7%9C%D7%AA%20AI%20%D7%9C%D7%95%D7%9E%D7%93%D7%AA.pdf

[^70]: https://education.tau.ac.il/AI_Generative

[^71]: https://www.pc.co.il/editorial/439576/

[^72]: https://www.prtfl.co.il/archives/236562

[^73]: https://www.ynet.co.il/digital/article/yokra14582532

[^74]: https://www.youtube.com/watch?v=W4Ua6XFfX9w

[^75]: https://security.utexas.edu/ai-tools

[^76]: https://www.abajournal.com/web/article/law-profs-trade-notes-as-law-school-write-generative-ai-policies

[^77]: https://www.linkedin.com/pulse/ai-fluency-framework-chan-meng-4taxc

[^78]: https://ringling.libguides.com/ai/framework

[^79]: https://www.digitaleducationcouncil.com/executive-briefings-event/classifying-ai-use-in-higher-education-dec-executive-briefing-010

[^80]: https://www.ucl.ac.uk/teaching-learning/generative-ai-hub/three-categories-genai-use-assessment

[^81]: https://ecampus.oregonstate.edu/faculty/artificial-intelligence-tools/blooms-taxonomy-revisited/

[^82]: https://onlinelearningconsortium.org/olc-insights/2025/10/blooms-for-ai-adoption/

[^83]: https://www.citadel.edu/ai-education/learning-in-the-age-of-ai-blooms-taxonomy-revisited/

[^84]: https://cdr.lib.unc.edu/downloads/05742652z?locale=en

[^85]: https://www.linkedin.com/pulse/ai-advantage-positioning-israeli-higher-education-through-fluman-9h3ff

[^86]: https://research.aimultiple.com/generative-ai-in-education/

[^87]: https://oercs.berkeley.edu/appropriate-use-generative-ai-tools

[^88]: https://www.youtube.com/watch?v=EljzyfdYkrc

[^89]: https://scale.stanford.edu/ai/repository/ai-education-higher-education-taxonomy-curriculum-reform-and-mission-knowledge

[^90]: https://hbsp.harvard.edu/inspiring-minds/student-use-cases-for-ai

[^91]: https://www.browsercat.com/post/chatgpt-usage-statistics-2020-2025

[^92]: https://clp.law.harvard.edu/knowledge-hub/insights/the-impact-of-artificial-intelligence-on-law-law-firms-business-models/

[^93]: https://www.nalp.org/future_of_the_legal_workplace

[^94]: https://www.lexisnexis.co.uk/insights/604376-embracing-ai-in-legal-education/index.html

[^95]: https://www.openu.ac.il/Lists/MediaServer_Documents/innovation/chais/2025/b3_1.pdf

[^96]: https://insideaipolicy.com/sites/insideaipolicy.com/files/documents/2024/aug/ai08062024.pdf

[^97]: https://law.stanford.edu/juelsgaard-intellectual-property-and-innovation-clinic/sls-and-stanford-ai-teaching-rersources-non-clinical/

[^98]: https://www.ox.ac.uk/research/support-researchers/research-practice/policy-generative-ai-research

[^99]: https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/

[^100]: https://onlinelearning.london.ac.uk/2025/07/01/menu-of-tools-and-resources/

[^101]: https://lawlibguides.sandiego.edu/c.php?g=1341754\&p=9892598

[^102]: https://studentaffairs.stanford.edu/AIWG/charge-academic-integrity-working-group

[^103]: https://www.reddit.com/r/harvardextension/comments/1mr7i7c/anyone_navigating_a_strict_no_ai_policy_in/

[^104]: https://libguides.law.illinois.edu/c.php?g=1325943\&p=9760539

[^105]: https://www.linkedin.com/posts/russell-pritchard72_melbournelawschool-legaleducation-aiinteaching-activity-7369682584034869248-NwAH

[^106]: https://www.cli.collaw.com/latest-news/2024/09/04/exploring-generative-ai-and-legal-education

[^107]: https://taggdaniel-aitraining.static.hf.space/1. Educational use of AI - Guidelines for FE and HE Staff.pdf

