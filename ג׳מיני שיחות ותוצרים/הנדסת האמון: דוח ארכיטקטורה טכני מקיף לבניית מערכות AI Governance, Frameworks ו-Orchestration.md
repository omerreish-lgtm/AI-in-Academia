# הנדסת האמון: דוח ארכיטקטורה טכני מקיף לבניית מערכות AI Governance, Frameworks ו-Orchestration

## תקציר מנהלים

ההטמעה המואצת של מודלי שפה גדולים (LLMs) ובינה מלאכותית יוצרת (Generative AI) בסביבות ארגוניות יצרה פרדיגמה חדשה בפיתוח תוכנה. המעבר מניסויים מבודדים (Proof of Concept) למערכות ייצור קריטיות מחייב שינוי תפיסתי ומבני בארכיטקטורת המידע. הדוח הנוכחי נכתב בתגובה לדרישה לצלול אל מתחת לפני השטח של המונחים העסקיים המקובלים, ולהציג "מדריך בנייה" טכני והנדסי לשלושת עמודי התווך של האקוסיסטם המודרני: **ממשל בינה מלאכותית (Governance)**, **תשתית העבודה (Framework)**, ו**תזמור (Orchestration)**.

בניגוד לדוחות אנליסטים המתמקדים במגמות שוק, דוח זה מפרק את המושגים לרכיביהם ההנדסיים: החל מהמתמטיקה של הווקטורים ומנגנוני הניתוב הסמנטיים, דרך תצורות של שערי גישה (Gateways) ומעקות בטיחות מבוססי קוד (Policy-as-Code), ועד לארכיטקטורות מורכבות של סוכנים אוטונומיים וניהול מצב (State Management). הניתוח משלב באופן הדוק את ההקשר הרגולטורי הייחודי לישראל, תוך התייחסות להנחיות מערך הסייבר הלאומי והרשות להגנת הפרטיות, ומתרגם דרישות משפטיות אלו לאילוצים ארכיטקטוניים קשיחים, כגון הצפנה משמרת-תבנית (FPE) ופרוקסי מקומי לסינון מידע רגיש. הדוח מזהה וממלא את הפערים הקיימים לרוב בספרות המקצועית, ומתמקד באתגרים התפעוליים של "היום שאחרי" (Day 2 Operations), כולל עלויות, נראות (Observability), והתמודדות עם תופעת ה-Shadow AI.

------

## חלק 1: הארכיטקטורה הטכנית של ממשל בינה מלאכותית (AI Governance)

ממשל בינה מלאכותית נתפס לעיתים בטעות כפונקציה משפטית או בירוקרטית גרידא. אולם, בראייה הנדסית, ממשל הוא **הנדסה של אילוצים**. במערכות דטרמיניסטיות מסורתיות, הלוגיקה מקודדת מראש ("אם X אז Y"). במערכות AI הסתברותיות, התוצאה אינה מובטחת, ולכן הממשל חייב להיות מיושם כשכבת בטון דטרמיניסטית העוטפת את המודל הגמיש. שכבה זו מורכבת מרכיבי תוכנה וחומרה שתפקידם לאכוף גבולות, לנטר תעבורה ולמנוע חריגות בזמן אמת.

### 1.1 שער הבינה המלאכותית (AI Gateway): נקודת האכיפה המרכזית

הרכיב הבסיסי ביותר בארכיטקטורת הממשל הטכני הוא **שער הבינה המלאכותית (AI Gateway)**. זהו רכיב תווכה (Middleware) המהווה אבולוציה של שער ה-API המסורתי, אשר תוכנן מחדש כדי להתמודד עם האתגרים הייחודיים של ייצור טוקנים הסתברותי.1

#### 1.1.1 ההבדל הארכיטקטוני משערי API מסורתיים

שערי API סטנדרטיים (כגון NGINX או Kong בגרסתם הבסיסית) מתייחסים למטען המידע (Payload) כאל "קופסה שחורה" בינארית. הם מנתבים בקשות על בסיס כותרות (Headers) וכתובות URL. לעומת זאת, AI Gateway חייב להיות "מודע למודל" (Model-Aware). הוא נדרש לפעול בשכבה הסמנטית, ולבצע אינספקציה של תוכן ההנחיה (Prompt) וההשלמה (Completion) בזמן אמת.

ההבדל הטכני המהותי בא לידי ביטוי במספר מישורים קריטיים:

1. מגבלת קצב מבוססת טוקנים (Token-Based Rate Limiting):

   במערכות מסורתיות, מגבלת העומס נקבעת לפי מספר הבקשות לשנייה (RPS). במערכות AI, בקשה בודדת יכולה לצרוך 10 טוקנים (שאילתה קצרה) או 100,000 טוקנים (סיכום מסמך משפטי), מה שמייצג עומס חישובי ועלות כספית שונים בתכלית. בנייה טכנית נכונה מחייבת הטמעה של אלגוריתמים מסוג "דלי טוקנים" (Token Bucket) אשר עוקבים אחר הצריכה בפועל. השער חייב ליירט את זרם התשובה (Streaming Response), לספור טוקנים בזמן אמת, ולנתק את החיבור באופן יזום אם המכסה נחצתה, עוד לפני שהמודל סיים את הפלט.3

2. שכבת הפשטה מאוחדת (Unified Abstraction Layer):

   ארגונים רבים משתמשים במספר מודלים במקביל (למשל, GPT-4 למשימות מורכבות ו-Claude 3 למשימות ניתוח טקסט ארוך). ה-AI Gateway משמש כ-Reverse Proxy המנרמל את ממשקי ה-API השונים של הספקים (OpenAI, Anthropic, Google, Cohere) לממשק קנוני אחיד.1 משמעות הדבר היא שצוותי הפיתוח כותבים קוד מול ה-Gateway בלבד, וצוותי התשתיות יכולים להחליף את המודל מאחורי הקלעים (למשל, משיקולי עלות או זמינות) מבלי לשבור את הקוד באפליקציה.

3. מטמון סמנטי (Semantic Caching):

   בניגוד למטמון HTTP רגיל המבוסס על התאמה מדויקת של כתובת URL, מטמון סמנטי פועל על בסיס משמעות. כאשר מתקבלת בקשה, השער מחשב את הווקטור (Embedding) של ההנחיה ומשווה אותו לווקטורים של בקשות קודמות השמורים במסד נתונים וקטורי (כגון Redis עם מודול וקטורי). אם נמצאה דמיון קוסינוס (Cosine Similarity) העולה על סף מסוים (למשל 0.95), השער מחזיר את התשובה השמורה במטמון. מנגנון זה מפחית דרמטית את זמני התגובה (Latnecy) ואת העלויות, שכן הוא חוסך קריאות יקרות למודל ה-LLM עבור שאלות נפוצות.5

#### 1.1.2 ארכיטקטורת "קצין המכס" (The Customs Officer Analogy)

כדי להמחיש את אופן הבנייה הטכנית, נהוג להשתמש באנלוגיה של "קצין מכס" בגבול בינלאומי.7 אנלוגיה זו מתורגמת לרכיבי תוכנה ספציפיים בשרשרת העיבוד:

| **שלב במכס**       | **רכיב טכני ב-AI Gateway**  | **תיאור הפעולה ההנדסית**                                     |
| ------------------ | --------------------------- | ------------------------------------------------------------ |
| **ביקורת דרכונים** | **Authentication & AuthZ**  | אימות זהות האפליקציה הקוראת (באמצעות mTLS, JWT או API Keys) ווידוא הרשאות גישה למודל ספציפי (למשל, רק למחלקת כספים יש גישה למודל המאומן על דוחות כספיים).9 |
| **שיקוף מזוודות**  | **Input Inspection**        | סריקת תוכן ההנחיה (Prompt) לאיתור "הברחות" כגון ניסיונות Jailbreak, הזרקת הנחיות זדוניות (Prompt Injection), או מידע אישי רגיש (PII) לפני שהמידע מגיע למודל. |
| **הסגר / החרמה**   | **Sanitization & Blocking** | חסימת הבקשה או החלפת מידע רגיש בערכי דמה (Placeholders) אם זוהתה הפרת מדיניות. |
| **אכיפת ויזה**     | **Policy Enforcement**      | ניתוב הבקשה למודל המתאים בהתאם ל"ויזה" של המשתמש (למשל, משתמשים חינמיים מנותבים למודל זול ומהיר, בעוד משתמשי פרימיום מנותבים למודל יקר ומדויק). |



### 1.2 מעקות בטיחות טכניים (Technical Guardrails): יישום מדיניות כקוד

בעוד שה-Gateway מנהל את התעבורה, ה**מעקות (Guardrails)** מנהלים את ההתנהגות. מעקות בטיחות הם ספריות תוכנה ושירותים היושבים בתווך שבין המשתמש למודל, ואוכפים כללים ספציפיים לגבי *מה* המודל רשאי לומר ו*כיצד* עליו לפעול. המעבר הוא ממדיניות כתובה ("אסור לתת ייעוץ פיננסי") לאכיפה אלגוריתמית.10

#### 1.2.1 ארכיטקטורת NVIDIA NeMo Guardrails

אחד המימושים המתקדמים ביותר בתחום זה הוא NVIDIA NeMo Guardrails, המציג את שפת **Colang** – שפת מידול ייעודית להגדרת דיאלוגים ואכיפת גבולות.11

כיצד בונים חסימה טכנית לייעוץ פיננסי?

במקום לסמוך על ה-System Prompt ("אנא אל תיתן ייעוץ פיננסי"), מפתח הממשל מגדיר זרימה דטרמיניסטית ב-Colang:

1. **הגדרת צורה קנונית (Canonical Form Definition):** המפתח מגדיר מה נחשב כ"בקשת ייעוץ פיננסי" על ידי מתן דוגמאות (Utterances). המערכת לומדת לזהות את הכוונה (Intent) הזו.

   Code snippet

   ```
   define user ask financial advice
     "Should I buy Tesla stock?"
     "Is Bitcoin a good investment?"
     "How should I allocate my 401k?"
   ```

2. **הגדרת הזרימה (Flow Definition):** נכתב חוק הקובע כיצד להגיב לזיהוי זה.

   Code snippet

   ```
   define flow
     user ask financial advice
     bot refuse financial advice
   ```

3. **יירוט בזמן ריצה (Runtime Interception):** כאשר משתמש שואל "האם כדאי לי למכור את המניות שלי?", המערכת ממירה את הטקסט לווקטור, מזהה דמיון גבוה לכוונה `user ask financial advice`, ומפעילה את תגובת הסירוב המוגדרת מראש (`bot refuse financial advice`) **מבלי לשלוח את השאלה כלל ל-LLM**. ארכיטקטורה זו חוסכת עלויות ומונעת סיכונים, שכן הסירוב הוא "מקודד קשיח" ולא מיוצר סטטיסטית.12

#### 1.2.2 מעקות קלט מול מעקות פלט (Input vs. Output Rails)

בבנייה הטכנית יש להבחין היכן ממוקם המעקה בשרשרת העיבוד, שכן לכך יש השלכות קריטיות על ביצועים ועלויות 14:

- **מעקות קלט (Input Rails):** מבוצעים *לפני* שהבקשה נשלחת למודל. תפקידם לזהות ניסיונות Jailbreak (למשל, "תתעלם מההוראות הקודמות"), חריגה מנושא (Topical Guidance), או הימצאות PII. חסימה בשלב זה חוסכת 100% מעלות האינפרנס (Inference) ומונעת מהמודל להיחשף למידע זדוני.
- **מעקות פלט (Output Rails):** מבוצעים *לאחר* שהמודל ייצר את התשובה, אך *לפני* שהיא מוצגת למשתמש. תפקידם לזהות הזיות (Hallucinations), רעילות (Toxicity) או דליפת מידע שלא נתפסה בשלב הקלט. שלב זה יקר חישובית ומוסיף לזמן ההמתנה (Latency), אך הוא הכרחי להבטחת איכות התוצר הסופי. טכניקות מתקדמות כוללות "בדיקה עצמית" (Self-Check), בה מודל נוסף בודק את התשובה של המודל הראשון מול המקורות.16

### 1.3 הנדסת פרטיות ומיסוך נתונים (PII Masking Pipeline)

עבור ארגונים הפועלים תחת רגולציה קפדנית, ובפרט בישראל, בניית הממשל מחייבת הטמעה של צנרת (Pipeline) לטיפול במידע אישי מזוהה (PII).

#### 1.3.1 צנרת המיסוך (The Masking Pipeline)

הבנייה הטכנית של מערכת מיסוך PII כוללת מספר שלבים עוקבים 17:

1. **גילוי (Detection - NER):** המערכת משתמשת במודל זיהוי ישויות (Named Entity Recognition) ייעודי, לרוב קטן ומהיר יותר מה-LLM הראשי (כגון ספריית Microsoft Presidio או מודל GLiNER), כדי לסרוק את הטקסט ולזהות ישויות כמו שמות, מספרי זהות ישראליים (9 ספרות עם ספרת ביקורת), מספרי כרטיסי אשראי וכתובות.19
2. **התמרה (Transformation - Masking):** הישויות שזוהו מוחלפות בערכי מציין מקום (Placeholders). אסטרטגיה נפוצה היא "מיסוך הפיך" (Reversible Masking):
   - *מקור:* "צור קשר עם אבי כהן בטלפון 054-1234567."
   - *ממוסך:* "צור קשר עם בטלפון [PHONE_1]."
3. **אינפרנס (Inference):** ההנחיה הממוסכת נשלחת למודל החיצוני (למשל, GPT-4 בענן). המודל מעבד את הלוגיקה והתחביר מבלי להיחשף למידע האישי האמיתי.
4. **דה-אנונימיזציה (Rehydration):** התשובה המתקבלת מהמודל ("שלחתי אימייל ל-...") מיורטת על ידי המערכת, וערכי מציין המקום מוחלפים חזרה לערכים המקוריים לפני שהתשובה מוצגת למשתמש הקצה.

### 1.4 ההקשר הרגולטורי הישראלי: אילוצים ארכיטקטוניים

מערך הסייבר הלאומי (INCD) והרשות להגנת הפרטיות (PPA) בישראל פרסמו הנחיות המשפיעות ישירות על הארכיטקטורה הטכנית.21 תיקון 13 לחוק הגנת הפרטיות יוצר אחריות קפדנית על מחזיקי מאגרי מידע, ודורש התייחסות הנדסית ספציפית:

#### 1.4.1 תושבות נתונים (Data Residency) ופרוקסי מקומי

הדרישה לשמור מידע רגיש בתחומי המדינה או להבטיח הגנה נאותה בעת העברתו לחו"ל מחייבת ארכיטקטורת **Local Proxy**.

- **הארכיטקטורה:** משתמש (ישראל) -> AI Gateway (אזור AWS תל אביב / חוות שרתים מקומית) -> מנוע סינון PII -> LLM (ענן ציבורי בחו"ל).
- **האילוץ:** ה-Gateway משמש כ"גבול דיגיטלי". שום מידע מזוהה (PII) לא מוצפן או לא ממוסך אינו רשאי לעבור מה-Gateway החוצה לשירותי הענן בארה"ב או אירופה. משמעות הדבר היא שמודל ה-NER שמבצע את המיסוך חייב לרוץ מקומית (On-Premise או בענן מקומי).23

#### 1.4.2 קונספט "כיפת הברזל הקיברנטית" (Cyber Dome)

אסטרטגיית ההגנה הלאומית של ישראל דוגלת בגישת "הגנה לעומק" (Defense in Depth). בהקשר של AI Governance, הדבר מתורגם לשימוש במודלים מקומיים כקו הגנה ראשון.25

- **מודל סיווג מקומי:** לפני ששאילתה מורכבת נשלחת למודל חזק ויקר בענן, היא עוברת דרך מודל קוד פתוח מקומי (כגון גרסה מכווננת של Llama 3 בעברית) המנתח את רמת הסיכון והרגישות שלה. רק שאילתות שעברו את סף הסינון המקומי מורשות לצאת החוצה.
- **הגנה מפני התקפות יריבות (Adversarial Defense):** כמו ש-WAF מגן מפני SQL Injection, ה-AI Gateway חייב לכלול מודלים לסיווג התקפות Prompt Injection (כגון מודלים המזהים תבניות "DAN" או מניפולציות לוגיות) ולחום אותן בזמן אמת.21

------

## חלק 2: מסגרת העבודה (AI Framework) - מנוע הידע

אם הממשל הוא מערכת הבלימה וההיגוי, הרי ש**מסגרת העבודה (AI Framework)** היא המנוע. זהו אוסף רכיבי התוכנה, מבני הנתונים ומנגנוני האחזור המאפשרים לבינה המלאכותית "לדעת" עובדות ארגוניות ו"לבצע" משימות. הבקשה הטכנית "כיצד לבנות" מפנה זרקור ישיר אל ארכיטקטורת **RAG (Retrieval-Augmented Generation)** ואל השימוש ב**מסדי נתונים וקטוריים**.

### 2.1 מסדי נתונים וקטוריים: הזיכרון לטווח ארוך

מסדי נתונים רלציוניים (SQL) שומרים שורות מובנות. מסגרות AI דורשות **מסד נתונים וקטורי** (כגון Pinecone, Milvus, Weaviate, או הרחבת pgvector) כדי לשמור "משמעות סמנטית".26

#### 2.1.1 שיכונים (Embeddings) והמרחב הרב-ממדי

הלב הטכני של המערכת הוא תהליך ה-**Embedding**. מודל שיכון (כגון `text-embedding-3-small` של OpenAI או מודלים רב-לשוניים של Cohere התומכים בעברית) ממיר פיסת טקסט לווקטור – רשימה ארוכה של מספרים עשרוניים (למשל, `[0.12, -0.98, 0.05,...]`).

- **המתמטיקה של הדמיון:** המערכת מאחזרת מידע לא על ידי חיפוש מילות מפתח מדויק, אלא על ידי חישוב **דמיון קוסינוס (Cosine Similarity)** בין ווקטור השאילתה לווקטורי המסמכים. דמיון קוסינוס מודד את הזווית בין שני ווקטורים במרחב רב-ממדי. ערך של 1.0 מציין זהות מלאה במשמעות; ערך של 0 מציין ניצבות (חוסר קשר מוחלט). שיטה זו מאפשרת למערכת להבין ש"רכב" ו"מכונית" הם מושגים קרובים מאוד, גם ללא חפיפה טקסטואלית.6

#### 2.1.2 אלגוריתמי אינדקס (HNSW)

במסגרת ארגונית המכילה מיליוני מסמכים, סריקה ליניארית (השוואת השאילתה לכל המסמכים) היא איטית מדי. הבנייה הטכנית מחייבת שימוש באינדקס מסוג **ANN (Approximate Nearest Neighbor)**. האלגוריתם הנפוץ ביותר בתעשייה הוא **HNSW (Hierarchical Navigable Small World)**.

- **איך זה עובד?** האלגוריתם בונה מבנה נתונים דמוי גרף רב-שכבתי. החיפוש מתחיל בשכבה העליונה עם "קפיצות גדולות" (התקרבות מהירה לאזור הכללי של התשובה במרחב הווקטורי) ויורד לשכבות נמוכות יותר לחיפוש מדויק ומקומי. זה מאפשר אחזור של המסמכים הרלוונטיים ביותר מתוך מיליונים בתוך מילי-שניות בודדות.27

### 2.2 ארכיטקטורת RAG: ביסוס המודל על ידע ארגוני

**RAG** היא הארכיטקטורה השלטת כיום בבניית יישומי AI ארגוניים. היא פותרת את בעיות ה"הזיה" (Hallucinations) ו"סף הידע" (Knowledge Cutoff) של המודלים.29 בניית מערכת RAG מחייבת הקמת צנרת נתונים (ETL) ייעודית.

#### 2.2.1 צנרת ההזנה (Ingestion Pipeline)

תהליך הנדסי זה הופך מסמכים גולמיים לידע וקטורי:

1. **טעינה (Loading):** מחברים (Connectors) שואבים מידע ממקורות שונים – קבצי PDF, אתרי SharePoint, בסיסי נתונים SQL ועוד. אתגר טכני מרכזי כאן הוא חילוץ טקסט נקי מקבצים מורכבים (כגון PDF סרוקים בעברית), הדורש לעיתים שימוש במנועי OCR מתקדמים.
2. **חיתוך (Chunking):** הטקסט מחולק למקטעים קטנים (למשל, 500 טוקנים). זוהי החלטה הנדסית קריטית; מקטעים גדולים מדי יבלבלו את המודל, וקטנים מדי יאבדו את ההקשר. טכניקת **Sliding Window** (חפיפה בין מקטעים, למשל 10%) מבטיחה שמשמעות לא תאבד בנקודות החיתוך.29
3. **שיכון (Embedding):** כל מקטע מומר לווקטור באמצעות המודל הנבחר.
4. **שמירה (Upsert):** הווקטור נשמר במסד הנתונים יחד עם המטא-דאטה שלו (מקור המסמך, עמוד, תאריך), המאפשר סינון עתידי (למשל, "חפש רק מסמכים משנת 2024").

#### 2.2.2 לולאת האחזור והייצור (The Retrieval & Generation Loop)

כאשר משתמש שואל שאלה:

1. **שיכון השאילתה:** שאלת המשתמש מומרת לווקטור.

2. **חיפוש היברידי (Hybrid Search):** המערכת מבצעת חיפוש וקטורי (למציאת הקשר סמנטי) ובמקביל חיפוש מילות מפתח (BM25) למציאת התאמות מדויקות (למשל, מק"ט מוצר). אלגוריתם דירוג מחדש (Reranker) משקלל את התוצאות משני המקורות.31

3. **בניית ההנחיה (Prompt Stuffing):** המסגרת (למשל באמצעות LangChain) בונה דינמית את ההנחיה שנשלחת למודל:

   > "אתה עוזר חכם. ענה על שאלת המשתמש אך ורק בהתבסס על המידע הבא: [הכנס כאן את המקטעים שאוחזרו]. שאלה: [שאלת המשתמש]"

4. **ייצור (Generation):** ה-LLM מייצר את התשובה בהתבסס על העובדות שסופקו לו.

### 2.3 כלי עבודה: LangChain ו-LlamaIndex

ה"דבק" שמחבר את כל הרכיבים הללו הוא ספריות קוד כגון **LangChain** או **LlamaIndex**.29

- **שרשראות (Chains):** ספריות אלו מאפשרות למפתחים להגדיר רצפי פעולות. אובייקט `RetrievalQAChain` ב-LangChain מנהל באופן אוטומטי את כל התהליך: קבלת השאלה, שיכון, אחזור מה-DB, ובניית הפרומפט ל-LLM.
- **הפשטה (Abstractions):** הן מספקות ממשק אחיד המאפשר להחליף רכיבי תשתית (למשל, לעבור מ-Pinecone ל-Elasticsearch) בשינוי שורת קוד אחת, ללא שכתוב הלוגיקה העסקית.

------

## חלק 3: תזמור (Orchestration) - המנצח על התזמורת

**תזמור (AI Orchestration)** הוא הלוגיקה של זמן הריצה שמנהלת תהליכים מורכבים ורב-שלביים. בעוד ה-Framework מספק את הכלים (אחזור, סיכום), התזמור מחליט *באיזה כלי להשתמש ומתי*. המעבר הוא ממעגל פשוט של "קלט -> פלט" לקבלת החלטות דינמית.33

### 3.1 ארכיטקטורות ניתוב: המתג החכם (The Intelligent Switch)

רכיב מפתח בתזמור הוא ה**ניתוב (Routing)**. לא כל שאילתה מצדיקה שימוש במודל היקר והאיטי ביותר (כגון GPT-4), ולא כל שאילתה דורשת חיפוש ב-RAG.

#### 3.1.1 ניתוב סמנטי (Semantic Routing)

זוהי טכניקה שבה "נתב" (Router) – לעיתים מודל סיווג קל או השוואת ווקטורים – מחליט על נתיב הבקשה.35

כיצד זה נבנה בקוד?

במקום לכתוב ביטויים רגולריים (Regex) אינסופיים כדי לתפוס "שאלות על חשבוניות", אנו מגדירים מסלול עם דוגמאות סמנטיות:

Python

```
# קוד קונספטואלי לניתוב סמנטי
routes =),
    Route(name="tech_support", examples=["המסך שלי שחור", "קיבלתי שגיאה 404", "לא מצליח להתחבר"]),
    Route(name="chitchat", examples=["שלום", "מה שלומך?", "בוקר טוב"])
]

# זמן ריצה
user_query = "למה חייבתם אותי פעמיים?"
query_vector = embed(user_query)

# סיווג
for route in routes:
    score = cosine_similarity(query_vector, route.embedding)
    if score > threshold:
        return route.execute()
```

ארכיטקטורה זו מאפשרת למערכת לנתב תעבורה באופן דינמי לסוכנים מתמחים: שאילתת "חיוב" תנותב לסוכן דטרמיניסטי המריץ SQL מול בסיס הנתונים הפיננסי, בעוד שאילתת "תמיכה טכנית" תנותב לסוכן RAG יצירתי הסורק את מדריכי המשתמש. שאילתת "Chitchat" תנותב למודל קטן ומהיר (כגון GPT-3.5 Turbo) לחסכון בעלויות.31

### 3.2 תזמור מול כוריאוגרפיה (Orchestration vs. Choreography)

הדוח חייב להבהיר את ההבדל הארכיטקטוני בין שתי תבניות העיצוב הללו, שהוא קריטי לבניית מערכות מורכבות.34

- **תזמור (המנצח):** ישנו "מוח" מרכזי (בדרך כלל סוכן LLM ראשי) המנהל את התהליך. הוא מחליט: "ראשית אחפש בגוגל, אחר כך אסכם את התוצאות, ולבסוף אשלח אימייל למשתמש". המצב (State) נשמר במקום אחד מרכזי. גישה זו קלה יותר לממשל, ניטור וביקורת (Audit), ולכן מועדפת בארגונים מוסדרים.
- **כוריאוגרפיה (הרקדנים):** סוכנים עצמאיים מגיבים לאירועים (Event-Driven). סוכן א' מניח קובץ בתיקייה; סוכן ב' מזהה את הקובץ ומעבד אותו. אין מנהל מרכזי. גישה זו סקלבילית יותר (ניתן להוסיף סוכנים בלי לשנות את המנצח), אך קשה מאוד לניפוי שגיאות (Debugging) ולהבנת תמונת המצב הכוללת במקרה של תקלה.

### 3.3 זרימות עבודה סוכניות (Agentic Workflows)

החזית הנוכחית של התזמור היא **Agentic AI**. כאן ה-LLM אינו רק מייצר טקסט, אלא מפעיל היגיון לגבי פעולות.15

#### 3.3.1 לולאת ReAct (Reason + Act)

זרימת העבודה של סוכן טיפוסי פועלת במעגל חוזר:

1. **מחשבה (Thought):** הסוכן מנתח את בקשת המשתמש ("הזמן לי טיסה לתל אביב").
2. **פעולה (Action):** הסוכן מחליט להפעיל כלי חיצוני (`lookup_flights`). פרוטוקול MCP (Model Context Protocol) הופך לסטנדרט המאפשר ל-LLM להתממשק לכלי תוכנה בצורה תקנית.39
3. **תצפית (Observation):** הכלי (API) מחזיר נתונים (רשימת טיסות).
4. **מחשבה שניה:** הסוכן מנתח את הנתונים ("מצאתי טיסה ב-17:00, אבל חסר לי מספר דרכון").
5. **תגובה סופית:** הסוכן פונה למשתמש להשלמת פרטים.

**מנוע התזמור:** לולאה זו מנוהלת על ידי מנוע תזמור (כגון LangGraph), אשר מתחזק את ה**מצב** (זיכרון התוכנית) ומטפל ב**התאוששות משגיאות** (אם ה-API נכשל, הסוכן יודע לנסות שוב או לבקש עזרה אנושית).40

------

## חלק 4: הניתוח החסר - המציאות התפעולית (Day 2 Operations)

המשתמש שאל: "מה לדעתך חסר בדוח שיצרת ביחס לאלו?". התשובה נעוצה בפער שבין "הקמת המערכת" (Day 1) לבין "הפעלת המערכת" (Day 2). רוב הדוחות הטכניים מתמקדים בבנייה, אך מזניחים את האתגרים התפעוליים הקריטיים שהופכים את המערכת לברת-קיימא.

### 4.1 כלכלת טוקנים (FinOps for AI)

רכיב חסר קריטי הוא הניהול הכלכלי של המערכת. תזמור טכני נכון חייב לכלול **ניתוב מבוסס עלות (Cost Routing)**.

- **הבעיה:** הנחיה ארוכה מאוד (למשל, סיכום ספר) שנשלחת למודל היקר ביותר תעלה הון.
- **הפתרון הטכני:** השער מחשב את אורך ההנחיה לפני השליחה. אם היא עולה על סף מסוים (למשל 10,000 טוקנים), הנתב משנמך אוטומטית את הבקשה למודל זול יותר (כגון GPT-3.5 או Claude Haiku) או מפעיל מנגנון דחיסה/סיכום מקדים. לוגיקה זו חייבת להיות חלק מה-AI Gateway בזמן אמת.31

### 4.2 נראות וניפוי שגיאות (Observability & Tracing)

ניפוי שגיאות במערכת דטרמיניסטית הוא פשוט (מסתכלים בלוגים). במערכת AI הסתברותית, לוגים רגילים אינם מספיקים.

- **החסר:** נדרשת מערכת **LLM Tracing** (באמצעות כלים כמו LangSmith, Arize Phoenix או OpenTelemetry המותאם ל-LLM). מערכת זו מציגה ויזואליזציה של השרשרת המלאה: *קלט משתמש -> בדיקת מעקה בטיחות -> החלטת נתב -> שאילתת מסד נתונים (אלו מסמכים חזרו?) -> הנחיה סופית ל-LLM -> פלט*.
- בלי ה-Trace הזה, לא ניתן להבין מדוע הבוט ענה תשובה שגויה – האם המסמך לא נמצא (בעיית אחזור)? האם המודל התבלבל (בעיית ייצור)? או שהמעקה חסם את התשובה (בעיית ממשל)?

### 4.3 בעיית ה-Shadow AI ויירוט רשתי

דוחות ממשל מתמקדים לרוב במדיניות, אך מפספסים את האכיפה הטכנית של **Shadow AI** (עובדים המשתמשים בכלים לא מאושרים).

- **הפתרון הטכני:** יירוט ברמת הרשת. על ידי הגדרת חוקי DNS או Firewall ארגוניים, כל תעבורה יוצאת לדומיינים של ספקי AI (כגון `api.openai.com`, `anthropic.com`) נחסמת אלא אם היא עוברת דרך ה-AI Gateway הארגוני המורשה. זה מאלץ את כל התעבורה לעבור דרך "קצין המכס" שהגדרנו בחלק 1, ומעניק לארגון נראות מלאה על השימוש ב-AI.1

### 4.4 שילוב אדם בלולאה (Human-in-the-Loop - HITL)

אוטומציה מלאה היא מסוכנת. ארכיטקטורה שלמה כוללת מנגנון HITL. אם מעקה הבטיחות מזהה ביטחון נמוך (Low Confidence) בתשובה או רגישות גבוהה, הזרימה לא צריכה רק "לחסום", אלא "לנתב לאדם".

- **הבנייה:** אינטגרציה טכנית בין מנוע התזמור למערכת ניהול קריאות (כגון ServiceNow או Jira). הסוכן פותח כרטיס, מצרף את השיחה והלוגיקה שלו, וממתין לאישור אנושי לפני ביצוע פעולה רגישה (כגון מחיקת נתונים או ביצוע העברה כספית).15

------

## סיכום: הארכיטקטורה המאוחדת

התשובה לשאלה "איך לבנות" אינה בחירה של כלי בודד, אלא בבניית **פלטפורמה אחודה**.

1. **ממשל (Governance):** בונה את החומה המגנה (Gateway) ואת השומרים הפנימיים (Guardrails).
2. **מסגרת עבודה (Framework):** מספקת את הזיכרון (Vector DB) ואת יכולת העיבוד (LLM).
3. **תזמור (Orchestration):** מספק את מערכת העצבים שמחברת את החלקים, ומנתבת את האותות (הנחיות) לשרירים הנכונים (כלים) בזמן הנכון.

עבור השוק הישראלי, פלטפורמה זו חייבת להיות מחוזקת ברכיבי תושבות נתונים (Data Residency) ובקרת פרטיות קפדנית. העתיד שייך לאלו שיתייחסו ל-AI לא כאל קסם, אלא כאל הנדסה – בניית מערכות שהן דטרמיניסטיות, ניתנות לצפייה, ומאובטחות כברירת מחדל (Secure by Design).

### השוואה טכנית מסכמת של הרכיבים

| **מאפיין**        | **AI Governance**          | **AI Framework**           | **AI Orchestration**           |
| ----------------- | -------------------------- | -------------------------- | ------------------------------ |
| **מטרה עיקרית**   | בטיחות, תאימות, שליטה      | אחזור ידע, הסקת מסקנות     | ניהול זרימת עבודה, קבלת החלטות |
| **רכיב מפתח**     | AI Gateway, Guardrails     | Vector DB, RAG Pipeline    | Semantic Router, Agents        |
| **סוג לוגיקה**    | דטרמיניסטית (חוקים, Regex) | הסתברותית (Embeddings)     | דינמית (לולאות מחשבה)          |
| **דוגמאות לכלים** | NVIDIA NeMo, Kong Gateway  | LangChain, Pinecone        | LangGraph, Semantic Kernel     |
| **מדד תפעולי**    | אחוז חסימות, PII Leaks     | Recall, Precision, Latency | Task Success Rate, עלות למשימה |